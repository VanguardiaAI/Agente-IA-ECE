#!/usr/bin/env python3
"""
Agente H√≠brido de Atenci√≥n al Cliente
Combina el sistema actual con capacidades multi-agente para mejor experiencia conversacional
ACTUALIZADO PARA FASE 3: Integrado con b√∫squeda h√≠brida y sistema FastAPI
"""

import asyncio
import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Optional, Any, Tuple
import logging

from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

# Importar servicios del sistema existente (FASE 3 INTEGRATION)
from services.database import db_service
from services.embedding_service import embedding_service
from services.conversation_logger import conversation_logger
from services.woocommerce import WooCommerceService
from services.knowledge_base import knowledge_service
from services.conversation_memory import memory_service
from services.bot_config_service import bot_config_service

# Importar el sistema multi-agente
from .multi_agent_system import CustomerServiceMultiAgent, ConversationContext

# Importar utilidades de WhatsApp
from src.utils.whatsapp_utils import format_escalation_message
from src.utils.whatsapp_product_formatter import format_products_for_whatsapp

# Importar detector de escalamiento
from .escalation_detector import escalation_detector

# Cargar variables de entorno
load_dotenv("env.agent")

@dataclass
class HybridConversationState:
    """Estado de conversaci√≥n h√≠brido que mantiene contexto persistente"""
    context: ConversationContext = field(default_factory=ConversationContext)
    conversation_history: List[Dict[str, str]] = field(default_factory=list)
    session_id: str = ""
    last_response_time: datetime = field(default_factory=datetime.now)
    conversation_mode: str = "adaptive"  # adaptive, simple, multi_agent
    user_preference: str = "auto"  # auto, detailed, quick
    satisfaction_score: float = 0.0

class HybridCustomerAgent:
    """Agente h√≠brido que combina simplicidad con capacidades avanzadas"""
    
    def __init__(self):
        self.llm_provider = os.getenv("LLM_PROVIDER", "openai")
        self.model_name = os.getenv("MODEL_NAME", "gpt-5")  # Usar GPT-5
        self.temperature = float(os.getenv("TEMPERATURE", "1.0"))
        self.max_completion_tokens = int(os.getenv("MAX_TOKENS", "4000"))
        
        # Inicializar LLMs
        self.main_llm = self._initialize_llm()
        self.quick_llm = self._initialize_quick_llm()
        
        # Servicios integrados del sistema existente
        self.db_service = db_service
        self.embedding_service = embedding_service
        self.conversation_logger = conversation_logger
        self.knowledge_service = knowledge_service
        self.memory_service = memory_service
        self.wc_service = None
        
        # Sistemas de agentes
        self.multi_agent_system = None
        
        # Estado de conversaci√≥n
        self.conversation_state = HybridConversationState()
        
        # Configuraci√≥n adaptativa
        self.enable_multi_agent = True
        self.enable_smart_routing = True
        self.enable_context_memory = True
        
        # Logger
        self.logger = logging.getLogger(__name__)
        
        # Configuraci√≥n del bot (se carga en initialize)
        self.bot_name = "Eva"  # Default
        self.company_name = "El Corte El√©ctrico"  # Default
        self.welcome_message = "Hola, ¬øen qu√© puedo ayudarte hoy?"  # Default
        
    def _initialize_llm(self):
        """Inicializa el LLM principal - siempre usa OpenAI"""
        return ChatOpenAI(
            model=self.model_name,
            temperature=self.temperature,
            max_completion_tokens=self.max_completion_tokens
        )
    
    def _initialize_quick_llm(self):
        """Inicializa un LLM r√°pido para respuestas simples - usa gpt-5-mini para econom√≠a"""
        return ChatOpenAI(
            model="gpt-5-mini",
            temperature=1.0,
            max_completion_tokens=1500
        )
    
    async def initialize(self):
        """Inicializa todos los componentes del agente h√≠brido"""
        self.logger.info("üöÄ Inicializando Agente H√≠brido...")
        
        # Verificar que los servicios base est√©n inicializados
        if not self.db_service.initialized:
            await self.db_service.initialize()
            
        if not self.embedding_service.initialized:
            await self.embedding_service.initialize()
        
        # Cargar configuraci√≥n del bot
        await self._load_bot_configuration()
        
        # Inicializar WooCommerce service
        self.wc_service = WooCommerceService()
        
        # Inicializar sistema multi-agente si est√° habilitado
        if self.enable_multi_agent:
            try:
                self.multi_agent_system = CustomerServiceMultiAgent(
                    bot_name=self.bot_name,
                    company_name=self.company_name
                )
                # Nota: Comentado temporalmente hasta revisar multi_agent_system
                # await self.multi_agent_system.initialize_mcp_client()
                self.logger.info("‚úÖ Sistema multi-agente preparado")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Error inicializando multi-agente: {e}")
                self.enable_multi_agent = False
        
        self.logger.info("‚úÖ Agente H√≠brido listo - Integrado con b√∫squeda h√≠brida")
    
    async def _load_bot_configuration(self):
        """Carga la configuraci√≥n del bot desde el servicio de configuraci√≥n"""
        try:
            # Cargar configuraci√≥n b√°sica del bot
            self.bot_name = await bot_config_service.get_setting("bot_name", "Eva")
            self.company_name = await bot_config_service.get_setting("company_name", "El Corte El√©ctrico")
            self.welcome_message = await bot_config_service.get_setting("welcome_message", "Hola, ¬øen qu√© puedo ayudarte hoy?")
            
            self.logger.info(f"‚úÖ Configuraci√≥n del bot cargada - Nombre: {self.bot_name}, Empresa: {self.company_name}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error cargando configuraci√≥n del bot, usando valores por defecto: {e}")
            # Los valores por defecto ya est√°n asignados en __init__
    
    async def process_message(self, message: str, user_id: str = "default", platform: str = "whatsapp") -> str:
        """Procesa un mensaje usando el enfoque h√≠brido adaptativo"""
        
        start_time = datetime.now()
        print(f"\nüë§ Usuario ({user_id}) [{platform}]: {message}")
        
        # Verificar si debemos escalar antes de procesar
        session_id = self.conversation_state.session_id or f"session_{user_id}"
        previous_response = self.conversation_state.conversation_history[-1]["content"] if self.conversation_state.conversation_history else None
        
        should_escalate, reason, suggested_msg = escalation_detector.should_escalate(
            message=message,
            session_id=session_id,
            previous_response=previous_response
        )
        
        if should_escalate:
            self.logger.info(f"üî¥ Escalamiento detectado: {reason}")
            return format_escalation_message(reason=reason, context={"suggested_message": suggested_msg}, platform=platform)
        
        # Actualizar historial
        self.conversation_state.conversation_history.append({
            "role": "user",
            "content": message,
            "timestamp": datetime.now().isoformat()
        })
        
        # An√°lisis r√°pido del mensaje para determinar estrategia
        strategy = await self._determine_response_strategy(message)
        
        print(f"üéØ Estrategia seleccionada: {strategy}")
        
        # Procesar seg√∫n la estrategia
        if strategy == "multi_agent" and self.enable_multi_agent and self.multi_agent_system:
            response = await self._process_with_multi_agent(message, platform)
        elif strategy == "tool_assisted":
            response = await self._process_with_tools(message, platform)
        elif strategy == "quick_response":
            response = await self._process_quick_response(message, platform)
        else:
            response = await self._process_standard_response(message, platform)
        
        # Actualizar historial con respuesta
        self.conversation_state.conversation_history.append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now().isoformat(),
            "strategy": strategy
        })
        
        # Actualizar contexto
        self._update_conversation_context(message, response)
        
        # Log a la base de datos
        try:
            await self.conversation_logger.log_message(
                session_id=self.conversation_state.session_id or f"session_{user_id}",
                user_id=user_id,
                message_type="conversation", 
                content=f"User: {message}\nAssistant: {response}",
                metadata={
                    "strategy": strategy,
                    "platform": platform,
                    "response_time_ms": int((datetime.now() - start_time).total_seconds() * 1000),
                    "user_message": message,
                    "assistant_response": response
                },
                strategy=strategy,
                response_time_ms=int((datetime.now() - start_time).total_seconds() * 1000)
            )
        except Exception as e:
            print(f"Error logging conversation: {e}")
        
        self.logger.info(f"ü§ñ {self.bot_name} ({strategy}): {response[:100]}...")
        
        # Aplicar formateo final seg√∫n la plataforma
        formatted_response = self._format_for_platform(response, platform)
        
        return formatted_response
    
    async def _call_gpt5_responses_api(self, prompt: str, system_prompt: str = "", max_tokens: int = 100) -> Any:
        """Llama a la Responses API de GPT-5 correctamente"""
        import aiohttp
        import json
        
        headers = {
            "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
            "Content-Type": "application/json"
        }
        
        # Combinar system y user prompt
        full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
        
        data = {
            "model": "gpt-5-mini",
            "input": full_prompt,
            "reasoning": {
                "effort": "minimal"  # Minimal para respuestas r√°pidas
            },
            "text": {
                "verbosity": "low"  # Respuestas concisas
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/responses",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        self.logger.error(f"Error en Responses API: {response.status} - {error_text}")
                        # Devolver objeto similar a Chat Completions para compatibilidad
                        return type('obj', (object,), {
                            'choices': [type('obj', (object,), {
                                'message': type('obj', (object,), {'content': ''})
                            })()]
                        })()
                    
                    result = await response.json()
                    
                    # Extraer el contenido de la respuesta GPT-5
                    content = ''
                    output = result.get('output', [])
                    if output and len(output) > 1:
                        message = output[1]  # El mensaje es el segundo elemento
                        if message.get('type') == 'message' and message.get('content'):
                            content_array = message.get('content', [])
                            if content_array and isinstance(content_array, list):
                                for content_item in content_array:
                                    if content_item.get('type') == 'output_text':
                                        content = content_item.get('text', '')
                                        break
                    
                    # Devolver objeto similar a Chat Completions para compatibilidad
                    return type('obj', (object,), {
                        'choices': [type('obj', (object,), {
                            'message': type('obj', (object,), {'content': content})
                        })()]
                    })()
                    
        except Exception as e:
            self.logger.error(f"Error llamando a Responses API: {e}")
            # Devolver objeto vac√≠o para compatibilidad
            return type('obj', (object,), {
                'choices': [type('obj', (object,), {
                    'message': type('obj', (object,), {'content': ''})
                })()]
            })()
    
    async def _determine_response_strategy(self, message: str) -> str:
        """Determina la estrategia de respuesta usando IA"""
        
        # Validar mensaje de entrada
        if not message or not message.strip():
            return "quick_response"
            
        # Truncar mensajes muy largos para el an√°lisis
        analysis_message = message[:1000] + "..." if len(message) > 1000 else message
        
        # Obtener contexto de conversaci√≥n reciente
        recent_context = self._get_recent_context_summary()
        
        strategy_prompt = f"""
Analiza la siguiente consulta de un cliente y determina la mejor estrategia de respuesta.

CONSULTA ACTUAL: "{analysis_message}"

{recent_context}

ESTRATEGIAS DISPONIBLES:

1. quick_response: Para saludos simples, despedidas, agradecimientos
   - Ejemplos: "Hola", "Gracias", "Adi√≥s", "Buenos d√≠as"

2. tool_assisted: Para cuando necesitas acceder a datos del sistema
   - B√∫squeda de productos NUEVOS (NO mencionados previamente)
   - Consultas de pedidos (cuando menciona email o n√∫mero de pedido)
   - Verificar stock o precios de productos NO mostrados a√∫n
   - Preguntas frecuentes (FAQ) sobre pol√≠ticas, horarios, env√≠os, devoluciones
   - Informaci√≥n de la base de conocimiento de la empresa

3. multi_agent: Para consultas complejas con m√∫ltiples intenciones
   - Ejemplos: "Quiero comprar velas Y consultar mi pedido", consultas con m√∫ltiples preguntas

4. standard_response: Para responder sobre informaci√≥n YA PRESENTADA o disponible en contexto
   - Selecci√≥n entre productos ya mostrados ("el m√°s barato", "el primero", "el segundo")
   - Comparaciones entre productos mencionados previamente
   - Detalles sobre productos ya mostrados
   - Preguntas de seguimiento sobre la conversaci√≥n
   - Cuando el usuario quiere elegir o preguntar sobre opciones ya presentadas

REGLAS CR√çTICAS:
- Si se mostraron productos y el usuario hace referencia a ellos, USA standard_response
- Referencias a productos mostrados incluyen: "el m√°s barato", "el primero", "ese", "el de X precio", "quiero el", etc.
- Solo usa tool_assisted para b√∫squedas de productos COMPLETAMENTE NUEVOS
- Analiza TODO el contexto - si hay productos en la conversaci√≥n reciente, probablemente se refiere a ellos

RESPONDE SOLO con el nombre de la estrategia: quick_response, tool_assisted, multi_agent, o standard_response
"""

        try:
            # Log para debug
            self.logger.info(f"üîç Determinando estrategia para: '{message[:100]}...'")
            
            # Usar Responses API para GPT-5
            response = await self._call_gpt5_responses_api(
                prompt=strategy_prompt,
                system_prompt="Eres un experto en an√°lisis de consultas de atenci√≥n al cliente. Determina la mejor estrategia de respuesta bas√°ndote en el tipo y complejidad de la consulta.",
                max_tokens=50
            )
            
            # Log detallado de la respuesta
            self.logger.info(f"üì° Respuesta de OpenAI: {response}")
            
            # Validar que tenemos una respuesta v√°lida
            if not response.choices or not response.choices[0].message or not response.choices[0].message.content:
                self.logger.warning("‚ö†Ô∏è Respuesta vac√≠a de IA, reintentando...")
                # Reintentar una vez m√°s
                await asyncio.sleep(1)
                response = await self._call_gpt5_responses_api(
                    prompt=f"Clasifica esta consulta: '{message}'",
                    system_prompt="Eres un experto en an√°lisis de consultas. Responde SOLO con: quick_response, tool_assisted, multi_agent, o standard_response",
                    max_tokens=20
                )
            
            strategy_response = response.choices[0].message.content.strip() if response.choices and response.choices[0].message else ""
            
            # Log de la respuesta original
            self.logger.info(f"üìù Respuesta de IA: '{strategy_response}'")
            
            # Limpiar y validar respuesta
            strategy = strategy_response.lower().replace(".", "").replace(",", "").strip()
            
            # Validar que la estrategia sea v√°lida
            valid_strategies = ["quick_response", "tool_assisted", "multi_agent", "standard_response"]
            if strategy in valid_strategies:
                self.logger.info(f"‚úÖ IA recomienda estrategia: {strategy}")
                return strategy
            else:
                self.logger.warning(f"‚ö†Ô∏è Estrategia inv√°lida de IA: '{strategy_response}', usando standard_response")
                # En lugar de fallback, usar standard_response que permite a la IA procesar con contexto
                return "standard_response"
                
        except Exception as e:
            self.logger.error(f"‚ùå Error en determinaci√≥n de estrategia IA: {type(e).__name__}: {e}")
            # En caso de error, usar standard_response para que la IA procese el mensaje
            return "standard_response"
    
    # ELIMINADO: _fallback_strategy_selection - La IA siempre debe decidir, no usar fallbacks mec√°nicos
    
    async def _process_with_multi_agent(self, message: str, platform: str = "whatsapp") -> str:
        """Procesa usando el sistema multi-agente"""
        try:
            return await self.multi_agent_system.process_message(message)
        except Exception as e:
            print(f"‚ö†Ô∏è Error en multi-agente: {e}")
            
            # Si el usuario est√° pidiendo hablar con alguien, escalar directamente
            message_lower = message.lower()
            if any(phrase in message_lower for phrase in ["hablar con alguien", "tengo un problema", "necesito ayuda", "quiero hablar"]):
                session_id = self.conversation_state.session_id or "default"
                should_escalate, reason, suggested = escalation_detector.should_escalate(
                    message=message,
                    session_id=session_id
                )
                if should_escalate:
                    return format_escalation_message(reason=reason, context={"suggested_message": suggested}, platform=platform)
            
            return await self._process_standard_response(message, platform)
    
    async def _process_with_tools(self, message: str, platform: str = "whatsapp") -> str:
        """Procesa usando b√∫squeda h√≠brida directa y servicios del sistema"""
        
        try:
            # SIEMPRE buscar en knowledge base primero para contexto RAG
            knowledge_context = await self._search_knowledge_base(message)
            
            # Clasificar el tipo de consulta
            query_type = await self._classify_query_type(message)
            self.logger.info(f"üìä Tipo de consulta detectado: {query_type} para mensaje: '{message}'")
            
            if query_type == "product_search":
                return await self._handle_product_search(message, platform, knowledge_context)
            elif query_type == "order_inquiry":
                return await self._handle_order_inquiry(message, platform, knowledge_context)
            elif query_type == "stock_check":
                return await self._handle_stock_check(message, platform, knowledge_context)
            elif query_type == "faq_inquiry":
                return await self._handle_faq_inquiry(message, platform, knowledge_context)
            else:
                return await self._process_standard_response(message, platform, knowledge_context)
                
        except Exception as e:
            self.logger.error(f"Error en procesamiento con herramientas: {e}")
            # Verificar si debemos escalar debido al error
            session_id = self.conversation_state.session_id or "default"
            should_escalate, reason, _ = escalation_detector.should_escalate(
                message=message,
                session_id=session_id,
                error_occurred=True
            )
            if should_escalate:
                return format_escalation_message(reason="technical_error", context={"error": str(e)}, platform=platform)
            return await self._process_standard_response(message, platform)
    
    async def _classify_query_type(self, message: str) -> str:
        """Clasifica el tipo de consulta del usuario usando IA"""
        
        # Obtener contexto reciente para mejor clasificaci√≥n
        recent_context = self._get_recent_context_summary()
        
        classification_prompt = f"""
Analiza esta consulta y clasif√≠cala en una de las categor√≠as disponibles.

CONSULTA: "{message}"

{recent_context}

CATEGOR√çAS:
1. order_inquiry - Consultas sobre pedidos existentes (estado, tracking, factura)
2. stock_check - Verificaci√≥n de disponibilidad de productos espec√≠ficos
3. faq_inquiry - Preguntas sobre pol√≠ticas, horarios, env√≠os, garant√≠as, devoluciones
4. product_search - B√∫squeda de productos nuevos (NO cuando se refiere a productos ya mostrados)
5. general - Cualquier otra consulta

IMPORTANTE:
- Si el usuario se refiere a productos YA MOSTRADOS en la conversaci√≥n, NO es product_search
- Solo clasifica como product_search cuando busca productos NUEVOS
- Considera el contexto completo de la conversaci√≥n

Responde SOLO con la categor√≠a: order_inquiry, stock_check, faq_inquiry, product_search o general
"""

        try:
            # Usar Responses API para clasificaci√≥n r√°pida
            response = await self._call_gpt5_responses_api(
                prompt=classification_prompt,
                system_prompt="Eres un experto en clasificaci√≥n de consultas de atenci√≥n al cliente.",
                max_tokens=20
            )
            
            if response.choices and response.choices[0].message:
                classification = response.choices[0].message.content.strip().lower()
                
                # Validar que sea una categor√≠a v√°lida
                valid_categories = ["order_inquiry", "stock_check", "faq_inquiry", "product_search", "general"]
                if classification in valid_categories:
                    return classification
                else:
                    self.logger.warning(f"Categor√≠a inv√°lida de IA: '{classification}', usando 'general'")
                    return "general"
            else:
                return "general"
                
        except Exception as e:
            self.logger.error(f"Error en clasificaci√≥n con IA: {e}")
            return "general"
    
    async def _handle_product_search(self, message: str, platform: str = "whatsapp", knowledge_context: str = "") -> str:
        """Maneja b√∫squedas de productos usando b√∫squeda h√≠brida con optimizaci√≥n IA"""
        try:
            self.logger.info(f"üîç B√öSQUEDA DE PRODUCTOS: '{message}'")
            
            # Usar el optimizador de b√∫squeda para analizar la consulta
            from services.search_optimizer import search_optimizer
            
            search_analysis = await search_optimizer.analyze_product_query(message)
            optimized_query = search_analysis.get('search_query', message)
            
            self.logger.info(f"ü§ñ Consulta optimizada: '{optimized_query}' (Original: '{message}')")
            self.logger.info(f"üìä An√°lisis: {search_analysis}")
            
            # Generar embedding para la consulta OPTIMIZADA
            embedding = await self.embedding_service.generate_embedding(optimized_query)
            
            # Realizar b√∫squeda h√≠brida con la consulta optimizada
            results = await self.db_service.hybrid_search(
                query_text=optimized_query,
                query_embedding=embedding,
                content_types=["product"],
                limit=20  # Buscar m√°s para luego filtrar con IA
            )
            
            # Si hay resultados, optimizarlos con IA
            if results and len(results) > 5:
                self.logger.info(f"üéØ Optimizando {len(results)} resultados con IA...")
                results = await search_optimizer.optimize_search_results(message, results, limit=5)
                self.logger.info(f"‚úÖ Resultados optimizados a {len(results)} productos m√°s relevantes")
            
            if not results:
                if platform == "wordpress":
                    return f"<p>Lo siento, no encontr√© productos que coincidan con '<strong>{message}</strong>'. ¬øPodr√≠as describir lo que buscas de otra manera?</p>"
                else:
                    return format_escalation_message(
                        reason="product_not_found",
                        context={"product_search": message},
                        platform=platform
                    )
            
            # Debug: Ver qu√© tipo de datos estamos recibiendo
            self.logger.info(f"Tipo de results: {type(results)}, Cantidad: {len(results)}")
            if results:
                self.logger.info(f"Tipo del primer resultado: {type(results[0])}")
                if isinstance(results[0], dict):
                    self.logger.info(f"Claves del primer resultado: {results[0].keys()}")
            
            # Agregar informaci√≥n relevante de knowledge base si existe
            additional_info = ""
            if knowledge_context:
                # Buscar informaci√≥n espec√≠fica de env√≠os, garant√≠as, etc.
                for doc in knowledge_context:
                    content = doc.get('content', '').lower()
                    if any(word in content for word in ['env√≠o', 'env√≠os', 'entrega', 'garant√≠a', 'devoluci√≥n', 'cambio']):
                        additional_info = doc.get('content', '')[:300]  # Primeros 300 caracteres
                        break
            
            # Formatear respuesta seg√∫n la plataforma
            if platform == "wordpress":
                # Importar utilidades de WordPress
                from src.utils.wordpress_utils import format_product_search_response
                
                # Convertir resultados al formato esperado por las utilidades
                products = []
                for result in results[:5]:
                    # Validar que result sea un diccionario
                    if isinstance(result, dict):
                        metadata = result.get('metadata', {})
                        images = metadata.get('images', [])
                        
                        # Debug images format
                        if images:
                            self.logger.info(f"Tipo de images: {type(images)}, Primer elemento: {type(images[0]) if images else 'empty'}")
                        
                        product = {
                            'name': result.get('title', 'Producto'),
                            'price': str(metadata.get('price', 0)),
                            'regular_price': str(metadata.get('regular_price', 0)),
                            'sale_price': str(metadata.get('sale_price', 0)),
                            'stock_status': metadata.get('stock_status', 'unknown'),
                            'permalink': metadata.get('permalink', ''),
                            'sku': metadata.get('sku', ''),
                            'images': images
                        }
                        products.append(product)
                    else:
                        self.logger.warning(f"Resultado inesperado tipo {type(result)}: {result}")
                
                if products:
                    return format_product_search_response(products, message)
                else:
                    return f"<p>Lo siento, encontr√© productos pero hubo un error al procesarlos. Por favor, intenta de nuevo.</p>"
            
            else:
                # Formato para WhatsApp - usar el formateador especializado
                # Convertir results al formato esperado por el formateador
                products = []
                for result in results:
                    if isinstance(result, dict):
                        products.append(result)
                
                # Usar el formateador especializado para WhatsApp
                response = format_products_for_whatsapp(products, message)
                
                # Agregar informaci√≥n adicional de knowledge base si existe
                if additional_info:
                    response += f"\n\nüí° *Informaci√≥n √∫til:*\n{additional_info}"
            
            return response
            
        except Exception as e:
            self.logger.error(f"Error en b√∫squeda de productos: {e}", exc_info=True)
            if platform == "wordpress":
                return "<p>Lo siento, tuve un problema al buscar productos. ¬øPodr√≠as intentar de nuevo o ser m√°s espec√≠fico en tu b√∫squeda?</p>"
            else:
                return format_escalation_message(
                    reason="technical_error",
                    context={"error": str(e), "product_search": message},
                    platform=platform
                )
    
    async def _handle_order_inquiry(self, message: str, platform: str = "whatsapp", knowledge_context: str = "") -> str:
        """Maneja consultas sobre pedidos usando las herramientas de WooCommerce"""
        try:
            # Extraer posible n√∫mero de pedido o email
            import re
            
            # Buscar n√∫mero de pedido
            order_numbers = re.findall(r'\b\d{3,}\b', message)
            
            # Buscar email
            emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', message)
            
            # Guardar en contexto si encontramos datos
            if emails and self.conversation_state.context:
                self.conversation_state.context.customer_email = emails[0]
            if order_numbers and self.conversation_state.context:
                self.conversation_state.context.order_number = order_numbers[0]
            
            # Verificar si el usuario se refiere a un pedido mencionado anteriormente
            message_lower = message.lower()
            refers_to_previous = any(phrase in message_lower for phrase in [
                "ese pedido", "el pedido", "sobre ese", "cuando llega", "tiempo de entrega",
                "cu√°ndo llegar√°", "fecha de entrega", "tracking", "seguimiento"
            ])
            
            # Si se refiere a un pedido anterior y tenemos contexto
            if refers_to_previous and self.conversation_state.context:
                # Buscar en el historial reciente si hay un pedido mencionado
                recent_messages = self.conversation_state.conversation_history[-6:] if self.conversation_state.conversation_history else []
                
                order_found = False
                no_orders_found = False
                saved_email = None
                
                for msg in recent_messages:
                    content = msg.get("content", "")
                    if msg.get("role") == "assistant":
                        # Verificar si se encontraron pedidos
                        if "Pedido #" in content:
                            # Extraer n√∫mero de pedido del mensaje anterior
                            import re
                            pedido_match = re.search(r'Pedido #(\d+)', content)
                            if pedido_match:
                                order_id = pedido_match.group(1)
                                order_found = True
                                
                                # Responder sobre el tiempo de entrega
                                response = f"üì¶ Sobre el pedido #{order_id}:\n\n"
                                response += "Los pedidos en estado 'Procesando' normalmente se env√≠an en 24-48 horas laborables.\n"
                                response += "Una vez enviado, recibir√°s un email con el n√∫mero de seguimiento.\n\n"
                                response += "Tiempo estimado de entrega:\n"
                                response += "- Pen√≠nsula: 24-72 horas desde el env√≠o\n"
                                response += "- Baleares/Canarias: 3-5 d√≠as laborables\n\n"
                                response += "¬øNecesitas m√°s informaci√≥n sobre este pedido?"
                                
                                return response
                        
                        # Verificar si NO se encontraron pedidos
                        elif "No encontr√© pedidos" in content or "no encontr√© ning√∫n pedido" in content.lower():
                            no_orders_found = True
                            # Intentar extraer el email mencionado
                            email_match = re.search(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', content)
                            if email_match:
                                saved_email = email_match.group(1)
                
                # Si previamente no se encontraron pedidos
                if no_orders_found and saved_email:
                    response = f"Lo siento, pero como te mencion√© antes, no encontr√© ning√∫n pedido asociado al email {saved_email}. "
                    
                    # Respuesta espec√≠fica seg√∫n la pregunta
                    if "tracking" in message_lower or "seguimiento" in message_lower:
                        response += "Sin un pedido existente, no puedo proporcionarte informaci√≥n de tracking.\n\n"
                    elif "cuando" in message_lower or "llega" in message_lower or "entrega" in message_lower:
                        response += "Sin un pedido existente, no puedo proporcionarte informaci√≥n sobre tiempos de entrega.\n\n"
                    else:
                        response += "No tengo informaci√≥n adicional sobre pedidos para ese email.\n\n"
                    
                    response += "Si crees que esto es un error o realizaste el pedido con otro email, por favor contacta con nuestro equipo de soporte:\n\n"
                    response += "üí¨ WhatsApp: https://wa.me/34614218122\n\n"
                    response += "Ellos podr√°n ayudarte a localizar tu pedido y proporcionarte la informaci√≥n que necesitas."
                    
                    return response
                
                # Si tenemos email guardado en contexto, usar ese
                if hasattr(self.conversation_state.context, 'customer_email') and self.conversation_state.context.customer_email:
                    emails = [self.conversation_state.context.customer_email]
            
            # Si solo tenemos email, buscar pedidos del cliente
            if emails and not order_numbers:
                email = emails[0]
                try:
                    # Usar el servicio WooCommerce para buscar pedidos
                    if not self.wc_service:
                        self.wc_service = WooCommerceService()
                    
                    # Buscar pedidos del cliente
                    orders = await self.wc_service.search_orders_by_customer(email)
                    
                    if orders:
                        if platform == "wordpress":
                            from src.utils.wordpress_utils import format_text_response
                            response = f"He encontrado {len(orders)} pedido(s) asociados a {email}:\n\n"
                            for i, order in enumerate(orders[:5], 1):  # M√°ximo 5 pedidos
                                order_id = order.get('id', 'N/A')
                                status = order.get('status', 'unknown')
                                date = order.get('date_created', '')[:10]  # Solo fecha
                                total = order.get('total', '0')
                                
                                # Traducir estado
                                status_es = {
                                    'pending': 'Pendiente',
                                    'processing': 'Procesando',
                                    'completed': 'Completado',
                                    'cancelled': 'Cancelado',
                                    'on-hold': 'En espera'
                                }.get(status, status)
                                
                                response += f"{i}. Pedido #{order_id}\n"
                                response += f"   Fecha: {date}\n"
                                response += f"   Total: {total}‚Ç¨\n"
                                response += f"   Estado: {status_es}\n\n"
                            
                            response += "¬øSobre cu√°l pedido necesitas informaci√≥n?"
                            return format_text_response(response, preserve_breaks=True)
                        else:
                            response = f"He encontrado {len(orders)} pedido(s) asociados a {email}:\n\n"
                            for i, order in enumerate(orders[:5], 1):  # M√°ximo 5 pedidos
                                order_id = order.get('id', 'N/A')
                                status = order.get('status', 'unknown')
                                date = order.get('date_created', '')[:10]  # Solo fecha
                                total = order.get('total', '0')
                                
                                # Traducir estado
                                status_es = {
                                    'pending': 'Pendiente',
                                    'processing': 'Procesando',
                                    'completed': 'Completado',
                                    'cancelled': 'Cancelado',
                                    'on-hold': 'En espera'
                                }.get(status, status)
                                
                                response += f"{i}. Pedido #{order_id}\n"
                                response += f"   üìÖ Fecha: {date}\n"
                                response += f"   üí∞ Total: {total}‚Ç¨\n"
                                response += f"   üì¶ Estado: {status_es}\n\n"
                            
                            response += "¬øSobre cu√°l pedido necesitas informaci√≥n?"
                            return response
                    else:
                        # Si no encuentra pedidos, escalar para verificaci√≥n manual
                        response = f"No encontr√© pedidos asociados al email {email} en mi sistema.\n\n" + format_escalation_message(
                            reason="order_help",
                            context={"email": email, "message": "Cliente busca pedidos con su email"},
                            platform=platform
                        )
                        if platform == "wordpress":
                            from src.utils.wordpress_utils import format_text_response
                            return format_text_response(response, preserve_breaks=True)
                        return response
                        
                except Exception as e:
                    self.logger.error(f"Error buscando pedidos: {e}")
                    return format_escalation_message(
                        reason="order_help",
                        context={"email": email},
                        platform=platform
                    )
            
            # Si tenemos ambos datos, buscar el pedido espec√≠fico
            elif order_numbers and emails:
                order_id = order_numbers[0]
                email = emails[0]
                response = f"Buscando el pedido #{order_id} para {email}... Por seguridad, esta consulta requiere verificaci√≥n adicional.\n\n" + format_escalation_message(
                    reason="order_help",
                    context={"order_id": order_id, "email": email},
                    platform=platform
                )
                if platform == "wordpress":
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response, preserve_breaks=True)
                return response
            
            # Si solo tenemos n√∫mero de pedido
            elif order_numbers:
                response = f"Para consultar el pedido #{order_numbers[0]}, necesito verificar tu identidad. ¬øPodr√≠as proporcionarme el email asociado a la compra?"
                if platform == "wordpress":
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response, preserve_breaks=True)
                return response
            
            # Si no tenemos ning√∫n dato
            else:
                response = "Para ayudarte con tu pedido, necesito:\n- El n√∫mero de pedido, o\n- El email usado en la compra\n\n¬øPodr√≠as proporcionarme alguno de estos datos?"
                if platform == "wordpress":
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response, preserve_breaks=True)
                return response
                
        except Exception as e:
            self.logger.error(f"Error en consulta de pedidos: {e}")
            return format_escalation_message(
                reason="order_help",
                context={"error": str(e)},
                platform=platform
            )
    
    async def _handle_stock_check(self, message: str, platform: str = "whatsapp", knowledge_context: str = "") -> str:
        """Maneja verificaciones de stock"""
        try:
            # Realizar b√∫squeda de productos primero
            embedding = await self.embedding_service.generate_embedding(message)
            
            results = await self.db_service.hybrid_search(
                query_text=message,
                query_embedding=embedding,
                content_types=["product"],
                limit=3
            )
            
            if not results:
                response = "No encontr√© ese producto. ¬øCu√°l buscas espec√≠ficamente?"
                if platform == "wordpress":
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response, preserve_breaks=True)
                return response
            
            response = ""
            
            for result in results[:2]:  # Solo mostrar 2 primeros
                title = result.get('title', 'Producto')
                metadata = result.get('metadata', {})
                stock_status = metadata.get('stock_status', 'unknown')
                stock_quantity = metadata.get('stock_quantity', 0)
                
                if platform == "wordpress":
                    if stock_status == 'instock':
                        if stock_quantity > 0:
                            response += f"{title} - {stock_quantity} unidades disponibles\n"
                        else:
                            response += f"{title} - En stock\n"
                    else:
                        response += f"{title} - Sin stock\n"
                else:
                    if stock_status == 'instock':
                        if stock_quantity > 0:
                            response += f"‚úÖ {title} - {stock_quantity} unidades\n"
                        else:
                            response += f"‚úÖ {title} - En stock\n"
                    else:
                        response += f"‚ùå {title} - Sin stock\n"
            
            if platform == "wordpress":
                from src.utils.wordpress_utils import format_text_response
                return format_text_response(response.strip(), preserve_breaks=True)
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"Error verificando stock: {e}")
            return format_escalation_message(
                reason="stock_error",
                context={"error": str(e), "query": message},
                platform=platform
            )
    
    async def _handle_faq_inquiry(self, message: str, platform: str = "whatsapp", knowledge_context: str = "") -> str:
        """Maneja preguntas frecuentes usando la knowledge base"""
        try:
            self.logger.info(f"üìö CONSULTA FAQ: '{message}'")
            
            # Si no tenemos contexto, buscar en knowledge base
            if not knowledge_context:
                knowledge_context = await self._search_knowledge_base(message)
            
            if not knowledge_context:
                # Si no encontramos nada en knowledge base, usar respuesta gen√©rica
                return await self._process_standard_response(message, platform)
            
            # Construir respuesta basada en el contexto encontrado
            response = ""
            
            # Tomar el documento m√°s relevante (el primero)
            most_relevant = knowledge_context[0]
            content = most_relevant.get('content', '')
            
            # Validar que tenemos contenido
            if not content or not content.strip():
                self.logger.warning(f"Empty content in knowledge base for query: '{message}'")
                return await self._process_standard_response(message, platform)
            
            # Formatear respuesta seg√∫n plataforma
            if platform == "wordpress":
                from src.utils.wordpress_utils import format_text_response
                response = f"<h4>{most_relevant.get('title', 'Informaci√≥n')}</h4>\n"
                response += f"<p>{content}</p>"
                
                # Si hay m√°s documentos relevantes, mencionarlos
                if len(knowledge_context) > 1:
                    response += "\n<p><em>Tambi√©n podr√≠a interesarte:</em></p>\n<ul>"
                    for doc in knowledge_context[1:3]:  # M√°ximo 2 adicionales
                        response += f"<li>{doc.get('title', 'Informaci√≥n adicional')}</li>"
                    response += "</ul>"
                
                return format_text_response(response, preserve_breaks=True)
            else:
                # WhatsApp
                response = f"üìã *{most_relevant.get('title', 'Informaci√≥n')}*\n\n"
                response += content
                
                # Si hay m√°s documentos relevantes, mencionarlos
                if len(knowledge_context) > 1:
                    response += "\n\nüí° _Tambi√©n podr√≠a interesarte:_"
                    for doc in knowledge_context[1:3]:  # M√°ximo 2 adicionales
                        response += f"\n‚Ä¢ {doc.get('title', 'Informaci√≥n adicional')}"
                
                return response
                
        except Exception as e:
            self.logger.error(f"Error en consulta FAQ: {e}")
            # Fallback a respuesta est√°ndar
            return await self._process_standard_response(message, platform)
    
    async def _process_quick_response(self, message: str, platform: str = "whatsapp") -> str:
        """Procesa respuestas r√°pidas para consultas simples"""
        
        quick_prompt = f"""
Eres {self.bot_name}, asistente virtual de {self.company_name}.

INFORMACI√ìN CR√çTICA:
- NO HAY TIENDA F√çSICA. Somos una tienda exclusivamente online.
- Tenemos m√°s de 4,500 productos el√©ctricos online.
- Web: https://elcorteelectrico.com
- WhatsApp directo: https://wa.me/34614218122

REGLAS: 
- Responde en m√°ximo 1-2 frases. S√© amable pero muy breve.
- NUNCA prometas avisar o notificar al cliente cuando algo est√© disponible
- NO ofrezcas enviar recordatorios o avisos futuros
- NO INVENTES informaci√≥n que no tengas
Cliente: {self.conversation_state.context.customer_name or 'Cliente'}
"""
        
        try:
            messages = [
                SystemMessage(content=quick_prompt),
                HumanMessage(content=f"Cliente dice: {message}")
            ]
            response = await self.quick_llm.ainvoke(messages)
            
            # Validar respuesta
            if not response.content or response.content.strip() == "":
                self.logger.warning(f"Empty quick response for message: '{message}'")
                return f"¬°Hola! Soy {self.bot_name} y estoy aqu√≠ para ayudarte. ¬øEn qu√© puedo asistirte hoy?"
            
            # Formatear respuesta seg√∫n la plataforma
            if platform == "wordpress":
                # Si la respuesta ya contiene HTML (generado por la IA), devolverla directamente
                import re
                if re.search(r'<[^>]+>', response.content):
                    return response.content
                else:
                    # Si es texto plano, formatearlo
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response.content, preserve_breaks=True)
            else:
                return response.content
        except Exception as e:
            self.logger.error(f"Error en respuesta r√°pida: {e}")
            return f"¬°Hola! Soy {self.bot_name} y estoy aqu√≠ para ayudarte. ¬øEn qu√© puedo asistirte hoy?"
    
    async def _search_knowledge_base(self, query: str) -> List[Dict[str, Any]]:
        """Buscar informaci√≥n relevante en la base de conocimientos"""
        try:
            # Buscar en knowledge base primero
            knowledge_results = await self.knowledge_service.search_knowledge(
                query=query,
                limit=3
            )
            
            # Si no hay resultados en knowledge, buscar en productos
            if not knowledge_results:
                embedding = await self.embedding_service.generate_embedding(query)
                product_results = await self.db_service.hybrid_search(
                    query_text=query,
                    query_embedding=embedding,
                    content_types=["product"],
                    limit=2
                )
                return product_results
            
            return knowledge_results
            
        except Exception as e:
            self.logger.error(f"Error buscando en knowledge base: {e}")
            return []
    
    async def _process_standard_response(self, message: str, platform: str = "whatsapp", knowledge_context: str = "") -> str:
        """Procesa usando el LLM principal con contexto de knowledge base"""
        
        # Confiar en la decisi√≥n de la IA - si llegamos aqu√≠ es porque la IA determin√≥
        # que esta es la mejor estrategia para responder
        
        # Guardar la plataforma actual para el prompt
        self._current_platform = platform
        
        # Si no se pas√≥ contexto, buscar informaci√≥n relevante
        if not knowledge_context:
            knowledge_context = await self._search_knowledge_base(message)
        
        # Crear prompt con contexto de knowledge base
        system_prompt = self._create_standard_prompt(message)
        
        # A√±adir contexto de knowledge base si existe
        if knowledge_context:
            context_text = "\n\nINFORMACI√ìN RELEVANTE DE LA BASE DE CONOCIMIENTOS:\n"
            for idx, doc in enumerate(knowledge_context, 1):
                doc_type = doc.get('doc_type', 'general')
                title = doc.get('title', 'Informaci√≥n')
                content = doc.get('content', '')
                
                # Limitar longitud del contenido
                if len(content) > 500:
                    content = content[:500] + "..."
                
                context_text += f"\n{idx}. [{doc_type.upper()}] {title}:\n{content}\n"
            
            system_prompt += context_text
            system_prompt += "\nUSA ESTA INFORMACI√ìN PERO RESPONDE DE FORMA BREVE. Si el cliente quiere m√°s detalles, los pedir√°."
        
        try:
            # Recuperar contexto de memoria si hay user_id
            user_context = None
            if self.conversation_state.context.customer_email:
                user_context = await self.memory_service.retrieve_user_context(
                    user_id=self.conversation_state.context.customer_email,
                    current_query=message
                )
            
            # A√±adir contexto de memoria al prompt si existe
            if user_context and user_context["interaction_count"] > 0:
                memory_prompt = self.memory_service.get_conversation_prompt(user_context)
                system_prompt = memory_prompt + "\n" + system_prompt
            
            messages = [SystemMessage(content=system_prompt)] + self._get_recent_context()
            messages.append(HumanMessage(content=message))
            
            # Filtrar mensajes vac√≠os
            valid_messages = []
            for msg in messages:
                if hasattr(msg, 'content') and msg.content and msg.content.strip():
                    valid_messages.append(msg)
            
            if not valid_messages:
                return f"Hola, soy {self.bot_name}, tu asistente de atenci√≥n al cliente. ¬øEn qu√© puedo ayudarte hoy?"
            
            response = await self.main_llm.ainvoke(valid_messages)
            
            # Validar respuesta
            if not response.content or response.content.strip() == "":
                self.logger.warning(f"Empty response from LLM for message: '{message}' - Using fallback")
                return self._get_fallback_response(message, platform)
            
            # Formatear respuesta seg√∫n la plataforma
            if platform == "wordpress":
                # Si la respuesta ya contiene HTML (generado por la IA), devolverla directamente
                import re
                if re.search(r'<[^>]+>', response.content):
                    return response.content
                else:
                    # Si es texto plano, formatearlo
                    from src.utils.wordpress_utils import format_text_response
                    return format_text_response(response.content, preserve_breaks=True)
            else:
                return response.content
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en respuesta est√°ndar: {e}")
            return self._get_fallback_response(message, platform)
    
    def _get_fallback_response(self, message: str, platform: str = "whatsapp") -> str:
        """Respuesta de emergencia cuando todo falla"""
        if "hola" in message.lower() or "buenos" in message.lower():
            response = f"¬°Hola! Soy {self.bot_name} de {self.company_name}. ¬øEn qu√© puedo ayudarte?"
        elif any(word in message.lower() for word in ["producto", "diferencial", "cable", "termo", "ventilador", "quiero", "busco", "necesito"]):
            response = "Tenemos m√°s de 4,500 productos el√©ctricos. ¬øQu√© necesitas espec√≠ficamente?"
        elif "pedido" in message.lower() or "orden" in message.lower():
            response = "Para consultar tu pedido necesito el n√∫mero de pedido y email."
        else:
            response = format_escalation_message(reason="general", platform=platform)
        
        # Formatear seg√∫n plataforma
        if platform == "wordpress":
            # Verificar si la respuesta contiene productos con formato markdown
            import re
            has_product_links = bool(re.search(r'\[.*?\]\(https?://.*?\)', response))
            
            if has_product_links:
                # Convertir markdown de productos a HTML
                from src.utils.wordpress_utils import convert_markdown_products_to_html
                return convert_markdown_products_to_html(response)
            else:
                # Respuesta normal sin productos
                from src.utils.wordpress_utils import format_text_response
                return format_text_response(response, preserve_breaks=True)
        else:
            return response
    

    
    def _create_standard_prompt(self, message: str) -> str:
        """Crea prompt para respuestas est√°ndar"""
        
        # Obtener contexto reciente para mejor comprensi√≥n
        recent_context = self._get_recent_context_summary()
        
        # Determinar formato seg√∫n plataforma
        platform = getattr(self, '_current_platform', 'whatsapp')
        format_instructions = ""
        
        if platform == "wordpress":
            format_instructions = """
FORMATO PARA WORDPRESS:
- USA HTML para enlaces: <a href="url">texto</a>
- NO uses formato Markdown [texto](url)
- Usa <strong> para negritas, NO asteriscos
- Usa <br> para saltos de l√≠nea si es necesario
- Los p√°rrafos deben estar en <p> tags
"""
        else:
            format_instructions = """
FORMATO PARA WHATSAPP:
- Usa formato Markdown para enlaces: [texto](url)
- Usa *texto* para negritas
- Usa saltos de l√≠nea normales
"""
        
        return f"""
Eres {self.bot_name}, asistente virtual de {self.company_name}. Eres una asistente conversacional natural.

CONTEXTO DE LA CONVERSACI√ìN:
{recent_context}

{format_instructions}

INFORMACI√ìN CR√çTICA DE LA EMPRESA:
- NO HAY TIENDA F√çSICA. Somos una tienda exclusivamente online.
- Tenemos m√°s de 4,500 productos el√©ctricos en nuestro cat√°logo online.
- Toda la venta es a trav√©s de la web: https://elcorteelectrico.com
- WhatsApp soporte: +34614218122
- Link directo WhatsApp: https://wa.me/34614218122

INSTRUCCIONES IMPORTANTES:
1. RESPONDE DE FORMA NATURAL Y CONVERSACIONAL, no como un robot
2. Si el usuario pregunta sobre productos YA MOSTRADOS, responde sobre ESOS productos espec√≠ficos
3. NO busques nuevos productos si el usuario est√° preguntando sobre los que ya viste
4. S√© espec√≠fica cuando hables de productos mostrados (usa nombres y precios)
5. Mant√©n la conversaci√≥n fluida con preguntas naturales cuando sea apropiado
6. Solo escala a WhatsApp si realmente no puedes ayudar
7. NUNCA prometas avisar al cliente cuando algo est√© listo o disponible
8. NO ofrezcas notificaciones, recordatorios o avisos futuros
9. Si preguntan por disponibilidad futura, sugiere que consulten m√°s adelante o contacten por WhatsApp
10. NUNCA INVENTES INFORMACI√ìN: Si no conoces un dato espec√≠fico (como el SKU de un producto), di claramente "No tengo esa informaci√≥n espec√≠fica" y ofrece buscar productos relacionados
11. NO HAY TIENDA F√çSICA: Si preguntan por la ubicaci√≥n o si pueden visitar, aclara que somos solo online
12. Cuando el usuario pida m√°s informaci√≥n sobre un producto espec√≠fico, SIEMPRE proporciona el enlace del producto si est√° disponible

INFORMACI√ìN DEL CLIENTE:
- Nombre: {self.conversation_state.context.customer_name or 'Cliente'}

DATOS B√ÅSICOS DE LA EMPRESA:
- Especialistas en material el√©ctrico  
- M√°s de 4,500 productos en cat√°logo
- Env√≠o gratis > 100‚Ç¨ (pen√≠nsula)
- Precios incluyen IVA (21%)
- WhatsApp soporte: +34 614 21 81 22
- Link directo WhatsApp: https://wa.me/34614218122
- NO INVENTES n√∫meros de tel√©fono (como 900) ni emails (como ventas@)
- Para soporte SIEMPRE proporciona el link de WhatsApp: https://wa.me/34614218122
- NO HAY TIENDA F√çSICA - Solo venta online

CONSULTA ACTUAL: {message}

Responde de forma natural, como lo har√≠a un vendedor experto y amable. Si el cliente pregunta sobre productos espec√≠ficos que ya se mostraron, habla de ESOS productos, no busques otros nuevos. Si no tienes informaci√≥n espec√≠fica sobre algo, s√© honesta y dilo claramente.
"""
    
    def _get_recent_context(self) -> List:
        """Obtiene contexto reciente de la conversaci√≥n"""
        recent_messages = []
        
        # Obtener √∫ltimos 4 mensajes para contexto
        for msg in self.conversation_state.conversation_history[-4:]:
            if msg["role"] == "user":
                recent_messages.append(HumanMessage(content=msg["content"]))
            else:
                recent_messages.append(AIMessage(content=msg["content"]))
        
        return recent_messages
    
    def _get_recent_context_summary(self) -> str:
        """Obtiene un resumen del contexto reciente de la conversaci√≥n"""
        if not self.conversation_state.conversation_history:
            return "No hay contexto previo"
        
        # Tomar √∫ltimos 3 intercambios
        recent = self.conversation_state.conversation_history[-6:]  # 3 pares user/assistant
        
        summary = "CONTEXTO DE CONVERSACI√ìN RECIENTE:\n"
        products_shown = False
        product_details = []
        
        for msg in recent:
            role = "Usuario" if msg["role"] == "user" else self.bot_name
            content = msg["content"]
            
            # Detectar si se mostraron productos
            if role == self.bot_name:
                # Buscar patrones de productos mostrados
                import re
                
                # Buscar productos con formato HTML (WordPress)
                product_matches = re.findall(r'<strong>([^<]+)</strong>.*?(\d+[,.]?\d*)\s*‚Ç¨', content)
                if product_matches:
                    products_shown = True
                    for i, (name, price) in enumerate(product_matches[:5], 1):
                        product_details.append(f"  {i}. {name} - {price}‚Ç¨")
                
                # Buscar productos con formato WhatsApp
                wa_product_matches = re.findall(r'(?:\d+\.\s*)?(?:\*)?([^*\n]+?)(?:\*)?(?:\s*-\s*|\n).*?(\d+[,.]?\d*)\s*‚Ç¨', content)
                if wa_product_matches and not product_matches:
                    products_shown = True
                    for i, (name, price) in enumerate(wa_product_matches[:5], 1):
                        product_details.append(f"  {i}. {name.strip()} - {price}‚Ç¨")
                
                # Si encontramos productos, resumir
                if products_shown and product_details:
                    summary += f"- {role}: [MOSTR√ì {len(product_details)} PRODUCTOS]:\n"
                    for detail in product_details[:3]:  # Mostrar m√°ximo 3 para contexto
                        summary += f"{detail}\n"
                    if len(product_details) > 3:
                        summary += f"  ... y {len(product_details) - 3} productos m√°s\n"
                    product_details = []  # Limpiar para siguiente mensaje
                else:
                    # Mensaje normal sin productos
                    content_preview = content[:100] + "..." if len(content) > 100 else content
                    summary += f"- {role}: {content_preview}\n"
            else:
                # Mensaje del usuario
                content_preview = content[:100] + "..." if len(content) > 100 else content
                summary += f"- {role}: {content_preview}\n"
        
        if products_shown:
            summary += "\n‚ö†Ô∏è IMPORTANTE: Se mostraron productos recientemente. Si el usuario se refiere a 'el m√°s barato', 'el primero', etc., se refiere a ESTOS productos.\n"
        
        return summary
    
    def _update_conversation_context(self, message: str, response: str):
        """Actualiza el contexto de la conversaci√≥n"""
        context = self.conversation_state.context
        
        # Extraer entidades b√°sicas
        message_lower = message.lower()
        
        # Extraer email
        import re
        email_pattern = r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b'
        emails = re.findall(email_pattern, message)
        if emails and not context.customer_email:
            context.customer_email = emails[0]
        
        # Extraer n√∫mero de pedido
        order_pattern = r'\b#?(\d{3,6})\b'
        orders = re.findall(order_pattern, message)
        if orders and not context.order_number:
            context.order_number = orders[0]
        
        # Extraer productos mencionados
        product_keywords = ['vela', 'perfume', 'aroma', 'lavanda', 'vainilla', 'canela', 'rosa']
        mentioned_products = [p for p in product_keywords if p in message_lower]
        if mentioned_products:
            context.preferred_products.extend(mentioned_products)
            # Remover duplicados
            context.preferred_products = list(set(context.preferred_products))
        
        # Actualizar resumen
        context.turn_count += 1
        context.conversation_summary += f" Usuario: {message[:50]}... Respuesta: {response[:50]}..."
        
        # Mantener resumen manejable
        if len(context.conversation_summary) > 500:
            context.conversation_summary = context.conversation_summary[-400:]
    

    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas de la conversaci√≥n"""
        
        # Obtener la √∫ltima estrategia usada
        last_strategy = "unknown"
        if self.conversation_state.conversation_history:
            for msg in reversed(self.conversation_state.conversation_history):
                if msg.get("role") == "assistant" and "strategy" in msg:
                    last_strategy = msg["strategy"]
                    break
        
        return {
            "turn_count": len(self.conversation_state.conversation_history) // 2,
            "current_intent": getattr(self.conversation_state.context, 'current_intent', 'unknown'),
            "last_strategy_used": last_strategy,
            "customer_info": {
                "name": self.conversation_state.context.customer_name,
                "email": self.conversation_state.context.customer_email,
                "order_number": getattr(self.conversation_state.context, 'order_number', None)
            },
            "entities_extracted": len(self.conversation_state.context.extracted_entities),
            "search_system": "hybrid_integrated",
            "multi_agent_enabled": self.enable_multi_agent,
            "conversation_mode": self.conversation_state.conversation_mode
        }
    
    def _format_for_platform(self, response: str, platform: str) -> str:
        """
        Aplica formateo espec√≠fico seg√∫n la plataforma
        
        Args:
            response: Respuesta original
            platform: Plataforma destino (whatsapp, wordpress, etc.)
            
        Returns:
            Respuesta formateada para la plataforma
        """
        if not response:
            return response
        
        if platform == "whatsapp":
            # Eliminar tags HTML si existen
            import re
            
            # Eliminar todos los tags HTML
            response = re.sub(r'<[^>]+>', '', response)
            
            # Convertir entidades HTML
            response = response.replace('&nbsp;', ' ')
            response = response.replace('&quot;', '"')
            response = response.replace('&apos;', "'")
            response = response.replace('&lt;', '<')
            response = response.replace('&gt;', '>')
            response = response.replace('&amp;', '&')
            
            # Limitar longitud para WhatsApp (4096 caracteres)
            if len(response) > 4000:
                response = response[:3997] + "..."
            
            # Asegurar que no haya espacios m√∫ltiples (pero preservar saltos de l√≠nea)
            # Reemplazar m√∫ltiples espacios horizontales con uno solo
            response = re.sub(r'[ \t]+', ' ', response)
            # Reemplazar m√°s de 2 saltos de l√≠nea consecutivos con solo 2
            response = re.sub(r'\n{3,}', '\n\n', response)
            # Limpiar espacios al final de las l√≠neas
            response = re.sub(r' +\n', '\n', response)
            
            # Agregar emoji de marca si no hay emojis en la respuesta
            if not any(ord(char) > 127 for char in response[:50]):  # Check primeros 50 chars
                response = "üí¨ " + response
            
        elif platform == "wordpress":
            # Para WordPress, NO agregar tags HTML - el widget los manejar√°
            # Solo limpiar asteriscos que pueden venir de otros formatos
            import re
            
            # NO convertir asteriscos a HTML - dejarlos para que el widget los procese
            # Solo asegurar que el formato sea limpio
            
            # Reemplazar m√∫ltiples espacios horizontales con uno solo
            response = re.sub(r'[ \t]+', ' ', response)
            # Reemplazar m√°s de 2 saltos de l√≠nea consecutivos con solo 2
            response = re.sub(r'\n{3,}', '\n\n', response)
            # Limpiar espacios al final de las l√≠neas
            response = re.sub(r' +\n', '\n', response)
        
        return response.strip()
    
    def reset_conversation(self):
        """Reinicia la conversaci√≥n"""
        self.conversation_state = HybridConversationState()
        print("üîÑ Conversaci√≥n reiniciada")

# Funci√≥n de prueba
async def test_hybrid_agent():
    """Prueba el agente h√≠brido"""
    print("üöÄ Iniciando Agente H√≠brido...")
    
    agent = HybridCustomerAgent()
    await agent.initialize()
    
    test_messages = [
        "Hola, soy Mar√≠a",
        "Busco velas de lavanda para mi casa",
        "¬øTienen productos en oferta?",
        "Quiero saber sobre mi pedido #1817, mi email es maria@test.com",
        "¬øCu√°nto cuesta el env√≠o a Barcelona?",
        "Tengo una queja sobre un producto defectuoso",
        "Gracias por tu ayuda, adi√≥s"
    ]
    
    print("\n" + "="*60)
    print("üß™ PRUEBA DEL AGENTE H√çBRIDO")
    print("="*60)
    
    for i, message in enumerate(test_messages, 1):
        print(f"\n--- MENSAJE {i} ---")
        response = await agent.process_message(message, user_id="test_user")
        print("\n" + "-"*40)
    
    # Mostrar estad√≠sticas finales
    stats = agent.get_conversation_stats()
    print(f"\nüìä Estad√≠sticas finales:")
    print(json.dumps(stats, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(test_hybrid_agent())