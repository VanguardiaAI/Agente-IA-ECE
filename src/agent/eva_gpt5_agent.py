#!/usr/bin/env python3
"""
EVA GPT-5 Agent - Sistema Multi-Agente Inteligente
Agente principal que orquesta todo el flujo de conversaci√≥n usando GPT-5
"""

import asyncio
import json
import os
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, field

from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient

# Cargar variables de entorno PRIMERO
load_dotenv()  # Carga .env
load_dotenv("env.agent")  # Carga env.agent

# Agentes especializados
from .gpt5_agents import (
    IntentClassifier,
    SearchAnalyzer,
    QueryGenerator,
    ResultsValidator,
    SearchRefiner,
    SynonymManager,
    ConversationState,
    SearchState,
    UserIntent
)

# Servicios del sistema
from services.database import HybridDatabaseService
from services.embedding_service import EmbeddingService
from services.conversation_logger import conversation_logger
from services.woocommerce import WooCommerceService
from services.knowledge_base import knowledge_service
from services.conversation_memory import memory_service
from services.bot_config_service import bot_config_service
from services.gpt5_client import GPT5Client, ReasoningEffort, Verbosity

# Utilidades
from src.utils.whatsapp_utils import format_escalation_message
from src.utils.whatsapp_product_formatter import format_products_for_whatsapp
from src.agent.escalation_detector import escalation_detector

logger = logging.getLogger(__name__)


class EvaGPT5Agent:
    """
    Agente principal EVA con GPT-5
    Orquesta todos los agentes especializados sin l√≥gica mec√°nica
    """
    
    def __init__(self):
        # Cliente GPT-5 principal
        self.gpt5 = GPT5Client()
        self.model = "gpt-5"  # USAR GPT-5 SIEMPRE
        
        # Agentes especializados
        self.intent_classifier = IntentClassifier()
        self.search_analyzer = SearchAnalyzer()
        self.query_generator = QueryGenerator()
        self.results_validator = ResultsValidator()
        self.search_refiner = SearchRefiner()
        self.synonym_manager = SynonymManager()
        
        # Servicios - crear instancias nuevas
        self.db_service = HybridDatabaseService()
        self.embedding_service = EmbeddingService()
        self.conversation_logger = conversation_logger
        self.wc_service = None
        self.knowledge_service = knowledge_service
        self.memory_service = memory_service
        
        # Cliente MCP para herramientas
        self.mcp_client = None
        self.mcp_tools = None
        
        # Estados de conversaci√≥n activos
        self.conversations: Dict[str, ConversationState] = {}
        
        # Configuraci√≥n
        self.bot_name = "Eva"
        self.company_name = "El Corte El√©ctrico"
        self.welcome_message = "Hola, ¬øen qu√© puedo ayudarte hoy?"
        self.max_search_attempts = 1  # Solo un intento para b√∫squedas r√°pidas
        
        # Informaci√≥n de contacto y empresa para respuestas r√°pidas
        self.contact_info = """
INFORMACI√ìN DE LA EMPRESA - EL CORTE EL√âCTRICO SOLUCIONES, S.L.:

SOBRE NOSOTROS:
- Especialistas en componentes el√©ctricos industriales y dom√©sticos
- M√°s de 4,000 productos de marcas certificadas
- Env√≠os a toda Espa√±a y Europa
- Asesoramiento t√©cnico especializado

CONTACTO (Tienda EXCLUSIVAMENTE ONLINE):
- Web: https://elcorteelectrico.com
- Email: ventas@elcorteelectrico.com
- Tel√©fono: +34 614 21 81 22
- Consultas t√©cnicas especializadas: +34 661 239 969
- Devoluciones: https://elcorteelectrico.com/devoluciones/

IMPORTANTE: NO tenemos tienda f√≠sica. Calle Laguna de Marquesado 47 es solo oficinas/almac√©n.

MARCAS PRINCIPALES:
- Protecci√≥n: Mersen, Cirprotec
- Automatizaci√≥n: B.E.G., Dinuy
- Iluminaci√≥n: Jung, Normalux, Polylux
- Ventilaci√≥n: Soler y Palau S&P
- Calefacci√≥n: Elnur Gabarr√≥n
- SAI/UPS: Salicru
- Material el√©ctrico: Tekox, Saci, Cellpack

SERVICIOS:
- Env√≠os: Toda Espa√±a y Europa (Nacex/DHL, seguro incluido)
- Tiempo entrega: Seg√∫n disponibilidad (hasta 4-5 d√≠as)
- M√©todos de pago: Transferencia, Tarjeta, Bizum, PayPal
- NO aceptamos contrareembolso

REDES SOCIALES:
- Facebook: https://www.facebook.com/people/El-Corte-El√©ctrico/61552544680168/
- Instagram: @corte.electrico
- LinkedIn: https://www.linkedin.com/in/el-corte-electrico-ecommerce-ba60a5282

NOTA IMPORTANTE: Para informaci√≥n detallada sobre pol√≠ticas de garant√≠a, devoluciones, env√≠os, y FAQs t√©cnicos, 
debo consultar la base de conocimiento para darte informaci√≥n precisa y actualizada.
"""
        
        # Logger
        self.logger = logging.getLogger(__name__)
        
    async def initialize(self):
        """Inicializa el agente y sus servicios"""
        self.logger.info("üöÄ Inicializando EVA GPT-5 Agent...")
        
        try:
            # Cargar configuraci√≥n del bot
            await self._load_bot_configuration()
            
            # Inicializar servicios base
            if not self.db_service.initialized:
                await self.db_service.initialize()
                
            if not self.embedding_service.initialized:
                await self.embedding_service.initialize()
                
            # Inicializar WooCommerce
            self.wc_service = WooCommerceService()
            
            # Cargar sin√≥nimos
            self.synonym_manager.load_synonyms()
            
            # Inicializar cliente MCP
            await self._initialize_mcp_client()
            
            self.logger.info("‚úÖ EVA GPT-5 Agent inicializado correctamente")
            
        except Exception as e:
            self.logger.error(f"Error inicializando EVA GPT-5 Agent: {e}")
            raise
            
    async def _load_bot_configuration(self):
        """Carga la configuraci√≥n del bot"""
        try:
            self.bot_name = await bot_config_service.get_setting("bot_name", "Eva")
            self.company_name = await bot_config_service.get_setting("company_name", "El Corte El√©ctrico")
            self.welcome_message = await bot_config_service.get_setting("welcome_message", self.welcome_message)
            self.logger.info(f"‚úÖ Configuraci√≥n cargada - Bot: {self.bot_name}")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error cargando configuraci√≥n: {e}")
            
    async def _initialize_mcp_client(self):
        """Inicializa el cliente MCP para usar las herramientas"""
        try:
            # Por ahora deshabilitamos MCP ya que no es cr√≠tico
            # TODO: Actualizar cuando tengamos la versi√≥n correcta de MultiServerMCPClient
            self.mcp_client = None
            self.mcp_tools = None
            self.logger.info("‚ö†Ô∏è Cliente MCP deshabilitado temporalmente")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error conectando cliente MCP: {e}")
            self.mcp_client = None
            self.mcp_tools = None
            
    async def process_message(
        self,
        message: str,
        user_id: str = "default",
        platform: str = "wordpress",
        session_id: Optional[str] = None
    ) -> str:
        """
        Procesa un mensaje del usuario usando el sistema multi-agente
        
        Args:
            message: Mensaje del usuario
            user_id: ID del usuario
            platform: Plataforma de origen
            session_id: ID de sesi√≥n (opcional)
            
        Returns:
            Respuesta formateada para el usuario
        """
        
        start_time = datetime.now()
        
        # Generar session_id si no se proporciona
        if not session_id:
            session_id = f"{user_id}_{int(start_time.timestamp())}"
        
        # No hacer correcci√≥n manual - dejar que la IA maneje errores ortogr√°ficos
            
        self.logger.info(f"üë§ Usuario ({user_id}) [{platform}]: {message}")
        
        # Obtener o crear estado de conversaci√≥n
        if session_id not in self.conversations:
            self.conversations[session_id] = ConversationState(
                session_id=session_id,
                user_id=user_id,
                platform=platform
            )
        
        conversation = self.conversations[session_id]
        conversation.add_message("user", message)
        
        try:
            # Verificar escalamiento
            should_escalate, reason, suggested_msg = escalation_detector.should_escalate(
                message=message,
                session_id=session_id,
                previous_response=None
            )
            
            if should_escalate:
                self.logger.info(f"üî¥ Escalamiento detectado: {reason}")
                return format_escalation_message(
                    reason=reason,
                    context={"suggested_message": suggested_msg},
                    platform=platform
                )
            
            # PASO 1: Clasificar intenci√≥n
            # SIEMPRE usar IA para clasificar - no usar l√≥gica mec√°nica
            intent_result = await self.intent_classifier.classify_intent(
                message,
                conversation.get_recent_messages()
            )
            
            conversation.current_intent = intent_result.intent
            conversation.intent_confidence = intent_result.confidence
            
            self.logger.info(
                f"üìå Intenci√≥n: {intent_result.intent.value} "
                f"(confianza: {intent_result.confidence:.2f})"
            )
            
            # PASO 2: Procesar seg√∫n intenci√≥n
            if intent_result.intent == UserIntent.PRODUCT_SEARCH:
                response = await self._handle_product_search(
                    message, conversation, platform
                )
                
            elif intent_result.intent == UserIntent.TECHNICAL_INFO:
                response = await self._handle_technical_info(
                    message, conversation, platform
                )
                
            elif intent_result.intent == UserIntent.ORDER_INQUIRY:
                response = await self._handle_order_inquiry(
                    message, conversation, intent_result.entities, platform
                )
                
            elif intent_result.intent == UserIntent.GREETING:
                response = await self._handle_greeting(conversation, platform)
                
            else:
                response = await self._handle_general_question(
                    message, conversation, platform
                )
            
            # Registrar respuesta
            conversation.add_message("assistant", response)
            
            # Guardar en memoria si est√° habilitada
            # TODO: Reactivar cuando memory_service est√© actualizado
            # try:
            #     await memory_service.save_conversation_turn(
            #         user_id=user_id,
            #         user_message=message,
            #         assistant_response=response,
            #         metadata={
            #             "intent": intent_result.intent.value,
            #             "confidence": intent_result.confidence,
            #             "platform": platform
            #         }
            #     )
            # except Exception as e:
            #     self.logger.warning(f"Error guardando en memoria: {e}")
            
            # Log de m√©tricas
            duration = (datetime.now() - start_time).total_seconds()
            self.logger.info(
                f"‚úÖ Respuesta generada en {duration:.2f}s | "
                f"Intent: {intent_result.intent.value} | "
                f"Turnos: {conversation.turn_count}"
            )
            
            return response
            
        except Exception as e:
            self.logger.error(f"‚ùå Error procesando mensaje: {e}", exc_info=True)
            
            # Log m√°s detallado del error
            self.logger.error(f"Sesi√≥n: {session_id}")
            self.logger.error(f"Usuario: {user_id}")
            self.logger.error(f"Mensaje: {message}")
            if conversation:
                self.logger.error(f"Estado conversaci√≥n: {conversation.search_state}")
                self.logger.error(f"Turnos: {conversation.turn_count}")
            
            error_response = (
                f"Lo siento, tuve un problema procesando tu solicitud. "
                f"¬øPodr√≠as reformular tu pregunta?"
            )
            
            conversation.add_message("assistant", error_response, {"error": str(e)})
            return error_response
            
    async def _handle_product_search(
        self,
        message: str,
        conversation: ConversationState,
        platform: str
    ) -> str:
        """
        Maneja b√∫squedas de productos con el flujo inteligente completo
        """
        
        # IMPORTANTE: Verificar si es una respuesta a una clarificaci√≥n anterior
        if conversation.search_state == SearchState.NEEDS_INFO and conversation.search_context:
            # Es una respuesta a nuestra pregunta de clarificaci√≥n
            self.logger.info("üìù Procesando respuesta a clarificaci√≥n")
            
            # Combinar la informaci√≥n anterior con la nueva
            search_context = conversation.search_context
            previous_query = search_context.original_query
            combined_query = f"{previous_query} {message}"
            
            # Actualizar el contexto con la informaci√≥n combinada
            search_context.original_query = combined_query
            search_context.has_clarified = True
            search_context.clarification_count += 1
            
            # IMPORTANTE: Despu√©s de 1 clarificaci√≥n, mostrar resultados siempre
            if search_context.clarification_count >= 1:
                self.logger.info("‚ö†Ô∏è Ya se pidi√≥ clarificaci√≥n - mostrando resultados disponibles")
                search_context.missing_info = []  # Limpiar para forzar mostrar resultados
            
            # Resetear intentos de b√∫squeda para permitir nueva b√∫squeda
            search_context.search_attempts = []
            
            # Proceder directamente a b√∫squeda
            conversation.update_search_state(SearchState.SEARCHING)
            
        else:
            # Es una nueva b√∫squeda
            search_context = conversation.create_search_context(message)
            search_context.original_query = message
            conversation.update_search_state(SearchState.ANALYZING)
        
        # PASO 1: Analizar la b√∫squeda (solo si no es respuesta a clarificaci√≥n)
        if conversation.search_state != SearchState.SEARCHING:
            self.logger.info("üîç Analizando b√∫squeda de productos...")
            analysis = await self.search_analyzer.analyze_search(
                search_context.original_query,  # Usar query combinada si es respuesta
                conversation.get_recent_messages()
            )
            
            # Guardar informaci√≥n extra√≠da
            search_context.extracted_info = {
                "product_type": analysis.product_type,
                "brand": analysis.brand,
                "specs": analysis.technical_specs,
                "has_enough_info": analysis.has_enough_info
            }
            # IMPORTANTE: Guardar missing_info para _handle_no_results
            if hasattr(analysis, 'missing_info') and analysis.missing_info:
                search_context.missing_info = analysis.missing_info
        else:
            # Si ya estamos buscando (respuesta a clarificaci√≥n), crear an√°lisis simple
            from dataclasses import dataclass
            @dataclass
            class SimpleAnalysis:
                product_type: str = ""
                brand: str = ""
                technical_specs: dict = None
                has_enough_info: bool = True
                clarification_needed: bool = False
                missing_info: list = None
            
            analysis = SimpleAnalysis(
                product_type=search_context.extracted_info.get("product_type", ""),
                has_enough_info=True  # Ya tenemos la info que pedimos
            )
        
        # Confiar en la IA - si dice que tiene suficiente info, proceder
        # No usar l√≥gica mec√°nica para forzar clarificaciones
        if analysis.has_enough_info:
            self.logger.info("‚úÖ La IA dice que tiene suficiente informaci√≥n - procediendo con b√∫squeda")
        else:
            self.logger.info("‚ö†Ô∏è La IA dice que falta informaci√≥n pero procederemos de todos modos")
            
        # PASO 2: Generar queries de b√∫squeda
        conversation.update_search_state(SearchState.SEARCHING)
        
        # Intentar b√∫squeda hasta max_attempts
        # REMOVIDO: Esta condici√≥n era redundante y bloqueaba b√∫squedas v√°lidas
        # La IA ya determin√≥ si puede buscar o no
        
        while search_context.can_retry(self.max_search_attempts):
            self.logger.info(
                f"üîé Intento de b√∫squeda {len(search_context.search_attempts) + 1}/"
                f"{self.max_search_attempts}"
            )
            
            # Generar queries
            if len(search_context.search_attempts) == 0:
                # Primera b√∫squeda
                # Usar la query combinada si es una respuesta a clarificaci√≥n
                query_to_use = search_context.original_query if search_context.has_clarified else message
                self.logger.info(f"üîé Generando queries para: '{query_to_use}'")
                queries = await self.query_generator.generate_queries(
                    query_to_use,
                    search_context.extracted_info,
                    analysis.product_type
                )
                self.logger.info(f"üìù Query principal generada: '{queries.primary_query}'")
            else:
                # B√∫squedas refinadas
                queries = await self.query_generator.optimize_for_retry(
                    [a["query"] for a in search_context.search_attempts],
                    search_context.refinement_feedback[-1] if search_context.refinement_feedback else "",
                    search_context.extracted_info
                )
            
            # Ejecutar b√∫squeda
            search_results = await self._execute_product_search(queries)
            
            # PASO 3: Validar resultados
            conversation.update_search_state(SearchState.VALIDATING)
            
            # DETECCI√ìN INTELIGENTE DE B√öSQUEDAS GENERALES
            # 1. Contar resultados que son categor√≠as vs productos
            category_results = [r for r in search_results if r.get('content_type') == 'category']
            product_results = [r for r in search_results if r.get('content_type') == 'product']
            
            # 2. Verificar si todos tienen el mismo score (se√±al de b√∫squeda general)
            scores = [r.get('score', r.get('rrf_score', 0)) for r in search_results[:10]]
            all_same_score = len(set(scores)) == 1 and len(scores) > 5
            
            # 3. Detectar si hay categor√≠as con muchos productos
            has_large_categories = False
            for r in category_results:
                content = str(r.get('content', '')).lower()
                # Buscar patrones como "n√∫mero de productos: X" o "X productos"
                import re
                match = re.search(r'(\d+)\s*producto', content)
                if match:
                    num_products = int(match.group(1))
                    if num_products >= 50:
                        has_large_categories = True
                        self.logger.info(f"üìä Categor√≠a con {num_products} productos detectada")
                        break
            
            # SI: hay categor√≠as grandes, todos tienen mismo score, y no especific√≥ detalles
            # ENTONCES: es una b√∫squeda muy general
            is_too_general = (
                (len(category_results) >= 1 or len(product_results) >= 10) and 
                all_same_score and
                (has_large_categories or len(product_results) >= 15) and
                len(message.split()) <= 5  # Mensaje muy corto, probablemente sin especificaciones
            )
            
            if is_too_general and not search_context.has_clarified:
                # Necesita clarificaci√≥n - la IA generar√° una pregunta espec√≠fica
                self.logger.info("üéØ Detectada b√∫squeda muy general - solicitando clarificaci√≥n")
                
                from dataclasses import dataclass
                @dataclass
                class GeneralSearchValidation:
                    is_valid: bool = False
                    relevance_score: float = 0.3
                    result_quality: str = "too_general"
                    issues: list = None
                    suggestions: list = None
                    best_matches: list = None
                    needs_refinement: bool = True
                    refinement_reason: str = "B√∫squeda muy general con cientos de productos posibles"
                
                validation = GeneralSearchValidation()
                search_context.needs_clarification_for_general = True
                
            elif len(search_results) >= 1:
                # Proceder normal - no es demasiado general
                from dataclasses import dataclass
                @dataclass
                class QuickValidation:
                    is_valid: bool = True
                    relevance_score: float = 0.9
                    result_quality: str = "good"
                    issues: list = None
                    suggestions: list = None
                    best_matches: list = None
                    needs_refinement: bool = False
                    refinement_reason: str = None
                
                validation = QuickValidation(
                    best_matches=list(range(min(8, len(search_results))))
                )
                self.logger.info(f"‚úÖ B√∫squeda espec√≠fica con {len(search_results)} resultados")
            else:
                # Validaci√≥n completa solo si es necesario
                validation = await self.results_validator.validate_results(
                    message,
                    search_results,
                    search_context.extracted_info
                )
            
            # Registrar intento
            search_context.add_attempt(
                queries.primary_query,
                search_results,
                validation.is_valid,
                validation.refinement_reason or ""
            )
            
            # Si los resultados son buenos, devolver
            # CAMBIO: Aceptar tambi√©n resultados "acceptable" si tenemos productos con buen score
            if validation.is_valid or (validation.result_quality in ["excellent", "good", "acceptable"] and len(search_results) > 0):
                conversation.update_search_state(SearchState.COMPLETED)
                
                # Seleccionar mejores resultados
                # Si validation.best_matches solo tiene pocos √≠ndices, expandir a m√°s productos relevantes
                if len(validation.best_matches) < 5 and len(search_results) > 3:
                    # Tomar los mejores seg√∫n validation + m√°s productos con buen score
                    best_indices = set(validation.best_matches)
                    
                    # A√±adir m√°s productos con score alto
                    for i, result in enumerate(search_results[:10]):
                        if i not in best_indices and result.get('rrf_score', result.get('score', 0)) > 0.5:
                            best_indices.add(i)
                            if len(best_indices) >= 6:  # Mostrar hasta 6 productos
                                break
                    
                    best_results = [
                        search_results[i] for i in sorted(best_indices)
                        if i < len(search_results)
                    ][:10]
                else:
                    # Usar los √≠ndices de validation
                    best_results = [
                        search_results[i] for i in validation.best_matches
                        if i < len(search_results)
                    ][:10]  # Mostrar hasta 10 productos
                
                return await self._format_product_results(
                    best_results,
                    platform,
                    search_context
                )
            
            # PASO 4: Manejar b√∫squedas muy generales
            # Solo pedir clarificaci√≥n si no hemos alcanzado el l√≠mite
            if validation.result_quality == "too_general" and not search_context.has_clarified and search_context.clarification_count < 1:
                # Es una b√∫squeda muy general - pedir clarificaci√≥n espec√≠fica
                conversation.update_search_state(SearchState.NEEDS_INFO)
                # NO marcar has_clarified aqu√≠ - se marca cuando el usuario responde
                
                # Usar la IA para generar una pregunta inteligente basada en los resultados
                clarification_prompt = f"""CONTEXTO: Somos El Corte El√©ctrico, tienda de material el√©ctrico.

El usuario busca: "{message}"

Encontr√© {len(category_results)} categor√≠as con cientos de productos y {len(product_results)} productos diferentes.

IMPORTANTE: 
- Si busca "autom√°tico" = interruptor magnetot√©rmico (protecci√≥n el√©ctrica)
- Si busca "diferencial" = interruptor diferencial (protecci√≥n contra fugas)
- SIEMPRE asume contexto de material el√©ctrico

Genera una pregunta breve y natural para ayudar a especificar qu√© tipo/caracter√≠sticas necesita."""
                
                clarification_response = await self.gpt5.create_response(
                    input_text=clarification_prompt,
                    model="gpt-5-mini",
                    reasoning_effort=ReasoningEffort.LOW,
                    verbosity=Verbosity.LOW,
                    max_completion_tokens=200
                )
                
                return clarification_response.content
                
            # PASO 5: Refinar si es necesario (pero no para b√∫squedas generales)
            elif validation.needs_refinement and search_context.can_retry() and validation.result_quality != "too_general":
                conversation.update_search_state(SearchState.REFINING)
                
                # Analizar qu√© tipo de refinamiento necesita
                refinement_analysis = await self.results_validator.analyze_refinement_needs(
                    validation,
                    search_context.search_attempts
                )
                
                # Refinar b√∫squeda
                refinement = await self.search_refiner.refine_search(
                    message,
                    search_context.extracted_info,
                    refinement_analysis,
                    search_context.search_attempts
                )
                
                # Guardar feedback para pr√≥xima iteraci√≥n
                search_context.refinement_feedback.append(refinement.reasoning)
                
                self.logger.info(f"üîÑ Refinando b√∫squeda: {refinement.new_approach}")
                
            else:
                # No se puede refinar m√°s o ya tenemos buenos resultados
                break
        
        # Si llegamos aqu√≠, no encontramos buenos resultados
        conversation.update_search_state(SearchState.FAILED)
        
        return await self._handle_no_results(
            message,
            search_context,
            platform
        )
        
    async def _execute_product_search(self, queries) -> List[Dict[str, Any]]:
        """Ejecuta b√∫squeda de productos usando las queries generadas"""
        
        all_results = []
        seen_ids = set()
        
        # Usar la query principal directamente sin procesamiento adicional
        # El QueryGenerator ya deber√≠a haber limpiado la query apropiadamente
        if queries.primary_query:
            self.logger.info(f"üîç B√∫squeda principal: '{queries.primary_query}'")
            results = await self._search_products(queries.primary_query)
            for r in results:
                if r.get('id') not in seen_ids:
                    all_results.append(r)
                    seen_ids.add(r.get('id'))
        
        # Si no hay suficientes resultados, intentar alternativas
        if len(all_results) < 5:
            for alt_query in queries.alternative_queries[:2]:
                if alt_query:
                    results = await self._search_products(alt_query)
                    for r in results:
                        if r.get('id') not in seen_ids:
                            all_results.append(r)
                            seen_ids.add(r.get('id'))
                            
                    if len(all_results) >= 10:
                        break
        
        return all_results[:20]  # M√°ximo 20 resultados
        
    async def _search_products(self, query: str) -> List[Dict[str, Any]]:
        """Ejecuta b√∫squeda usando las herramientas MCP"""
        
        try:
            if self.mcp_tools and 'search_products' in self.mcp_tools:
                # Usar herramienta MCP
                result = await self.mcp_tools['search_products'](
                    query=query,
                    limit=10,
                    use_hybrid=True
                )
                
                # Parsear resultado si es string
                if isinstance(result, str):
                    # Extraer productos del formato de texto
                    products = []
                    lines = result.split('\n')
                    for line in lines:
                        if line.strip() and not line.startswith('‚ú®'):
                            # Parsear l√≠nea de producto
                            # Formato esperado: "1. T√≠tulo - ‚Ç¨XX.XX - ‚úì En stock"
                            import re
                            match = re.match(r'^\d+\.\s+(.+?)\s+-\s+‚Ç¨([\d.]+)\s+-\s+(.+)$', line)
                            if match:
                                products.append({
                                    'title': match.group(1),
                                    'metadata': {
                                        'price': float(match.group(2)),
                                        'stock_status': 'instock' if '‚úì' in match.group(3) else 'outofstock'
                                    }
                                })
                    return products
                else:
                    return result
                    
            else:
                # Fallback: b√∫squeda SOLO DE TEXTO en base de datos
                # NO USAR EMBEDDINGS NI B√öSQUEDA H√çBRIDA
                self.logger.info(f"üîç Usando b√∫squeda de SOLO TEXTO para: '{query}'")
                results = await self.db_service.text_search(
                    query_text=query,
                    content_types=['product'],
                    limit=15  # M√°s resultados para compensar
                )
                
                return results
                
        except Exception as e:
            self.logger.error(f"Error en b√∫squeda: {e}")
            return []
            
    async def _format_product_results(
        self,
        products: List[Dict[str, Any]],
        platform: str,
        search_context: Any
    ) -> str:
        """Formatea los resultados de productos para el usuario"""
        
        if platform == "whatsapp":
            return format_products_for_whatsapp(products)
        else:
            # Formato HTML para web/wordpress
            from src.utils.wordpress_utils import format_product_search_response
            
            # Convertir productos al formato esperado por wordpress_utils
            wp_products = []
            for product in products:
                metadata = product.get('metadata', {})
                
                # Asegurar que las im√°genes est√©n en el formato correcto
                images = metadata.get('images', [])
                if images and isinstance(images[0], str):
                    # Convertir URLs simples a formato dict
                    images = [{'src': img} for img in images if img]
                elif not images:
                    images = []
                    
                wp_product = {
                    'name': product.get('title', 'Producto'),
                    'price': str(metadata.get('price', 0)),
                    'regular_price': str(metadata.get('regular_price', metadata.get('price', 0))),
                    'sale_price': str(metadata.get('sale_price', '')),
                    'stock_status': metadata.get('stock_status', 'unknown'),
                    'permalink': metadata.get('permalink', ''),
                    'sku': metadata.get('sku', ''),
                    'images': images,
                    'relevance_score': product.get('rrf_score', product.get('score', 0))  # Para ordenar por relevancia
                }
                wp_products.append(wp_product)
                
            if wp_products:
                # Usar el formato HTML bonito
                return format_product_search_response(
                    wp_products, 
                    search_context.original_query if hasattr(search_context, 'original_query') else "tu b√∫squeda"
                )
            else:
                return "<p>Lo siento, encontr√© productos pero hubo un error al procesarlos.</p>"
            
    async def _handle_no_results(
        self,
        query: str,
        search_context: Any,
        platform: str
    ) -> str:
        """Maneja el caso cuando no se encuentran resultados satisfactorios"""
        
        # Si es porque falta informaci√≥n, generar pregunta de clarificaci√≥n directa
        if search_context.missing_info and not search_context.has_clarified:
            # Usar el search_refiner para generar una pregunta natural
            clarification = await self.search_refiner.generate_user_clarification(
                search_context.extracted_info,
                search_context.missing_info
            )
            return clarification
        
        # Si ya clarificamos pero no hay resultados
        attempts_summary = []
        for attempt in search_context.search_attempts:
            attempts_summary.append(f"- {attempt['query']}: {attempt['results_count']} resultados")
        
        response = (
            f"Lo siento, no pude encontrar exactamente lo que buscas.\n\n"
        )
        
        if search_context.missing_info:
            response += (
                f"Para ayudarte mejor, necesitar√≠a saber: "
                f"{', '.join(search_context.missing_info)}.\n\n"
            )
        
        response += "¬øPodr√≠as darme m√°s detalles sobre lo que necesitas?"
        
        return response
        
    async def _handle_technical_info(
        self,
        message: str,
        conversation: ConversationState,
        platform: str
    ) -> str:
        """Maneja consultas t√©cnicas sobre productos"""
        
        try:
            # Verificar si es sobre productos mostrados recientemente
            recent_messages = conversation.get_recent_messages()
            
            # Buscar si hay productos en el contexto reciente
            products_info = []
            products_context = None
            
            for msg in reversed(recent_messages[-3:]):
                if msg.get('role') == 'assistant' and 'eva-product-card' in msg.get('content', ''):
                    products_context = msg.get('content', '')
                    # Extraer informaci√≥n de productos del HTML
                    import re
                    
                    # Extraer t√≠tulos de productos (usan h3, no h5)
                    titles = re.findall(r'<h3[^>]*>([^<]+)</h3>', products_context)
                    
                    # Extraer precios (buscar el span con el precio final)
                    prices = re.findall(r'‚Ç¨(\d+(?:\.\d+)?)', products_context)
                    
                    # Extraer permalinks para m√°s informaci√≥n
                    permalinks = re.findall(r'href="([^"]+)"[^>]*class="eva-product-link"', products_context)
                    
                    # Combinar informaci√≥n
                    for i in range(len(titles)):
                        product_info = {
                            'title': titles[i] if i < len(titles) else '',
                            'price': f"‚Ç¨{prices[i]}" if i < len(prices) else '',
                            'url': permalinks[i] if i < len(permalinks) else ''
                        }
                        products_info.append(product_info)
                    
                    break
            
            # Si pide explicar diferencias de productos mostrados
            if products_info and any(keyword in message.lower() for keyword in ['diferencias', 'diferencia', 'comparar', 'mejor', 'cu√°l', 'recomienda']):
                # Preparar informaci√≥n de productos para el prompt
                products_text = "\n\n".join([
                    f"Producto {i+1}: {p['title']}\n"
                    f"Precio: {p['price']}"
                    for i, p in enumerate(products_info[:10])  # M√°ximo 10 productos
                ])
                
                # Usar GPT-5 para analizar y comparar productos
                prompt = f"""Eres un experto en material el√©ctrico. El usuario acaba de ver estos productos y pregunta: "{message}"

PRODUCTOS MOSTRADOS:
{products_text}

IMPORTANTE: Estos son productos de El Corte El√©ctrico, tienda de material el√©ctrico.

Genera una respuesta √∫til y pr√°ctica que:
- Si pide diferencias: compara caracter√≠sticas t√©cnicas principales
- Si pide recomendaci√≥n: sugiere el m√°s adecuado seg√∫n el caso de uso
- Si pregunta cu√°l es mejor: analiza pros/contras de cada uno
- Mant√©n un tono profesional y conocedor

Responde de forma clara y concisa."""

                response = await self.gpt5.create_response(
                    input_text=prompt,
                    model="gpt-5-mini",
                    reasoning_effort=ReasoningEffort.LOW,
                    verbosity=Verbosity.MEDIUM,
                    max_completion_tokens=600
                )
                
                return response.content
            
            # Si no es sobre productos mostrados, buscar en knowledge base
            # Buscar informaci√≥n t√©cnica
            results = await self.knowledge_service.search_knowledge(
                query=message,
                limit=3
            )
            
            if results:
                # Usar GPT-5 para generar respuesta basada en el conocimiento
                context = "\n\n".join([r.get('content', '') for r in results[:2]])
                
                prompt = f"""Bas√°ndote en esta informaci√≥n t√©cnica, responde la pregunta del usuario.

Pregunta: {message}

Informaci√≥n disponible:
{context}

IMPORTANTE - NUNCA INVENTES PRODUCTOS:
- NO generes listados de productos con precios, SKUs o stock
- NO inventes especificaciones de productos espec√≠ficos
- SI el usuario busca productos, indica que debe usar la b√∫squeda de productos
- SOLO proporciona informaci√≥n t√©cnica general basada en el conocimiento disponible

Genera una respuesta clara, concisa y t√©cnicamente correcta.
Si la informaci√≥n no es suficiente, ind√≠calo honestamente."""

                response = await self.gpt5.create_response(
                    input_text=prompt,
                    model=self.model,
                    reasoning_effort=ReasoningEffort.LOW,
                    verbosity=Verbosity.MEDIUM,
                    max_completion_tokens=500
                )
                
                return response.content
                
            else:
                return (
                    "No encontr√© informaci√≥n t√©cnica espec√≠fica sobre eso en nuestra base de conocimiento. "
                    "¬øPodr√≠as ser m√°s espec√≠fico o preguntarme sobre otro aspecto t√©cnico?"
                )
                
        except Exception as e:
            self.logger.error(f"Error buscando informaci√≥n t√©cnica: {e}")
            return (
                "Disculpa, tuve un problema buscando esa informaci√≥n t√©cnica. "
                "¬øPodr√≠as reformular tu pregunta?"
            )
            
    async def _handle_order_inquiry(
        self,
        message: str,
        conversation: ConversationState,
        entities: Dict[str, Any],
        platform: str
    ) -> str:
        """Maneja consultas sobre pedidos"""
        
        try:
            # Extraer informaci√≥n del pedido
            order_info = await self.intent_classifier.extract_order_info(message)
            
            order_number = order_info.get('order_number') or entities.get('order_number')
            email = order_info.get('email')
            
            if not order_number:
                return (
                    "Para consultar tu pedido, necesito el n√∫mero de pedido. "
                    "Por ejemplo: 'Mi pedido #1234' o 'Estado del pedido 1234'."
                )
            
            # Intentar obtener n√∫mero limpio
            import re
            match = re.search(r'#?(\d+)', str(order_number))
            if match:
                order_id = int(match.group(1))
            else:
                return f"No pude identificar un n√∫mero de pedido v√°lido en '{order_number}'."
            
            # Usar herramienta MCP si est√° disponible
            if self.mcp_tools and 'get_order_with_validation' in self.mcp_tools:
                if not email:
                    return (
                        f"Para verificar tu pedido #{order_id}, necesito que me proporciones "
                        f"el email asociado a la compra por seguridad."
                    )
                
                result = await self.mcp_tools['get_order_with_validation'](
                    order_id=order_id,
                    customer_email=email
                )
                
                return result
                
            elif self.mcp_tools and 'get_order_status' in self.mcp_tools:
                # Sin validaci√≥n de email
                result = await self.mcp_tools['get_order_status'](
                    order_id=order_id
                )
                
                return result
                
            else:
                return (
                    "Lo siento, no puedo acceder a la informaci√≥n de pedidos en este momento. "
                    "Por favor, contacta con atenci√≥n al cliente."
                )
                
        except Exception as e:
            self.logger.error(f"Error consultando pedido: {e}")
            return (
                "Hubo un error al consultar tu pedido. "
                "Por favor, verifica el n√∫mero e intenta nuevamente."
            )
            
    async def _handle_greeting(
        self,
        conversation: ConversationState,
        platform: str
    ) -> str:
        """Maneja saludos"""
        
        # Verificar si es primera interacci√≥n
        if conversation.turn_count <= 1:
            return self.welcome_message
        else:
            return "¬°Hola de nuevo! ¬øEn qu√© puedo ayudarte?"
            
    async def _handle_general_question(
        self,
        message: str,
        conversation: ConversationState,
        platform: str
    ) -> str:
        """Maneja preguntas generales usando GPT-5"""
        
        # Usar GPT-5 para responder de forma inteligente
        context = f"""Eres {self.bot_name}, asistente virtual de {self.company_name}, 
una tienda de material el√©ctrico. Responde la siguiente pregunta de forma √∫til y profesional.

{self.contact_info}

Pregunta: {message}

IMPORTANTE: Si preguntan por contacto, ubicaci√≥n, tel√©fono, email, redes sociales o tienda f√≠sica, 
usa la informaci√≥n proporcionada arriba. NO inventes informaci√≥n."""

        try:
            response = await self.gpt5.create_response(
                input_text=context,
                model=self.model,
                reasoning_effort=ReasoningEffort.MEDIUM,
                verbosity=Verbosity.MEDIUM,
                max_completion_tokens=300
            )
            
            return response.content
            
        except:
            return (
                "Gracias por tu pregunta. Para informaci√≥n espec√≠fica sobre horarios, "
                "env√≠os o pol√≠ticas de la tienda, te recomiendo contactar directamente "
                "con nuestro servicio de atenci√≥n al cliente."
            )
    


# Para compatibilidad con el sistema actual
hybrid_agent = EvaGPT5Agent()