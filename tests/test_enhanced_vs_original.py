#!/usr/bin/env python3
"""
Script de ComparaciÃ³n: Agente Original vs Agente Mejorado
Prueba ambos agentes con los mismos casos de uso para mostrar mejoras
"""

import asyncio
import time
from typing import List, Dict, Any

from simple_agent import SimpleCustomerAgent
from enhanced_agent import EnhancedCustomerAgent
from dotenv import load_dotenv

# Cargar configuraciÃ³n
load_dotenv("env.agent")

class AgentComparison:
    def __init__(self):
        self.original_agent = None
        self.enhanced_agent = None
        self.test_results = []
        
    async def initialize_agents(self):
        """Inicializa ambos agentes"""
        print("ğŸ”§ Inicializando agentes...")
        
        # Agente original
        print("   ğŸ“¤ Inicializando agente original...")
        self.original_agent = SimpleCustomerAgent()
        await self.original_agent.initialize_mcp_client()
        
        # Agente mejorado
        print("   âœ¨ Inicializando agente mejorado...")
        self.enhanced_agent = EnhancedCustomerAgent()
        await self.enhanced_agent.initialize_mcp_client()
        
        print("âœ… Ambos agentes inicializados\n")
    
    def get_test_scenarios(self) -> List[Dict[str, Any]]:
        """Define escenarios de prueba problemÃ¡ticos"""
        return [
            {
                "name": "Consulta Vaga de Producto",
                "description": "El usuario busca algo sin ser especÃ­fico",
                "messages": ["Hola, busco algo para regalar"],
                "expected_improvement": "Mejor manejo de consultas ambiguas"
            },
            {
                "name": "Lenguaje Natural Informal",
                "description": "Usuario usa lenguaje coloquial",
                "messages": ["Oye, Â¿tienes velas que huelan rico?"],
                "expected_improvement": "ComprensiÃ³n mejorada de lenguaje informal"
            },
            {
                "name": "MÃºltiples Intenciones",
                "description": "Usuario menciona varias cosas en un mensaje",
                "messages": ["Quiero comprar velas de lavanda y tambiÃ©n saber sobre mi pedido #123"],
                "expected_improvement": "DetecciÃ³n de mÃºltiples intenciones"
            },
            {
                "name": "Contexto Conversacional",
                "description": "ConversaciÃ³n que requiere recordar contexto",
                "messages": [
                    "Busco velas aromÃ¡ticas",
                    "De las que me mostraste, Â¿cuÃ¡l recomiendas?",
                    "Â¿Y el precio incluye envÃ­o?"
                ],
                "expected_improvement": "Manejo de contexto y referencias"
            },
            {
                "name": "SinÃ³nimos y Variaciones",
                "description": "Usuario usa sinÃ³nimos para lo mismo",
                "messages": ["Â¿Tienen fragancias para el hogar?"],
                "expected_improvement": "Mejor reconocimiento de sinÃ³nimos"
            },
            {
                "name": "Pregunta Indirecta",
                "description": "Usuario hace pregunta sin ser directo",
                "messages": ["Mi casa huele un poco raro, Â¿quÃ© me sugieres?"],
                "expected_improvement": "Inferencia de necesidades implÃ­citas"
            },
            {
                "name": "InformaciÃ³n Parcial",
                "description": "Usuario da informaciÃ³n incompleta",
                "messages": ["Mi pedido no ha llegado"],
                "expected_improvement": "Mejor manejo de informaciÃ³n faltante"
            },
            {
                "name": "ExpresiÃ³n Emocional",
                "description": "Usuario expresa emociones",
                "messages": ["Estoy algo preocupada porque mi pedido no llega"],
                "expected_improvement": "Mejor respuesta empÃ¡tica"
            }
        ]
    
    async def test_agent(self, agent, agent_name: str, scenario: Dict[str, Any]) -> Dict[str, Any]:
        """Prueba un agente con un escenario especÃ­fico"""
        print(f"   ğŸ§ª Probando {agent_name}...")
        
        start_time = time.time()
        responses = []
        
        try:
            for message in scenario["messages"]:
                if hasattr(agent, 'process_message'):
                    response = await agent.process_message(message)
                else:
                    # Para agentes que no tienen process_message, usar mÃ©todo alternativo
                    response = await agent.handle_general_help()
                
                responses.append({
                    "message": message,
                    "response": response
                })
            
            execution_time = time.time() - start_time
            
            return {
                "agent": agent_name,
                "success": True,
                "responses": responses,
                "execution_time": execution_time,
                "context_info": getattr(agent, 'context', None)
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            return {
                "agent": agent_name,
                "success": False,
                "error": str(e),
                "responses": responses,
                "execution_time": execution_time
            }
    
    async def run_comparison(self):
        """Ejecuta la comparaciÃ³n completa"""
        print("ğŸ†š COMPARACIÃ“N DE AGENTES")
        print("=" * 60)
        print("ğŸ“Š Probando diferentes escenarios problemÃ¡ticos")
        print("ğŸ’¡ El agente mejorado deberÃ­a manejar mejor cada caso")
        print("=" * 60)
        
        scenarios = self.get_test_scenarios()
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\nğŸ§ª ESCENARIO {i}: {scenario['name']}")
            print(f"ğŸ“ {scenario['description']}")
            print(f"ğŸ’­ Mejora esperada: {scenario['expected_improvement']}")
            print(f"ğŸ’¬ Mensajes: {scenario['messages']}")
            print("-" * 50)
            
            # Probar agente original
            original_result = await self.test_agent(
                self.original_agent, 
                "Agente Original", 
                scenario
            )
            
            # Probar agente mejorado
            enhanced_result = await self.test_agent(
                self.enhanced_agent, 
                "Agente Mejorado", 
                scenario
            )
            
            # Mostrar resultados
            self.display_comparison_results(original_result, enhanced_result, scenario)
            
            # Guardar resultados
            self.test_results.append({
                "scenario": scenario,
                "original": original_result,
                "enhanced": enhanced_result
            })
            
            print("\n" + "="*60)
    
    def display_comparison_results(self, original_result: Dict, enhanced_result: Dict, scenario: Dict):
        """Muestra los resultados de comparaciÃ³n"""
        print(f"\nğŸ“Š RESULTADOS PARA: {scenario['name']}")
        print("-" * 40)
        
        # Agente Original
        print("ğŸ”¸ AGENTE ORIGINAL:")
        if original_result["success"]:
            print(f"   â±ï¸  Tiempo: {original_result['execution_time']:.2f}s")
            for resp in original_result["responses"]:
                print(f"   ğŸ‘¤ Usuario: {resp['message']}")
                print(f"   ğŸ¤– Bot: {resp['response'][:150]}...")
                print()
        else:
            print(f"   âŒ Error: {original_result.get('error', 'Unknown')}")
        
        print("-" * 30)
        
        # Agente Mejorado
        print("âœ¨ AGENTE MEJORADO:")
        if enhanced_result["success"]:
            print(f"   â±ï¸  Tiempo: {enhanced_result['execution_time']:.2f}s")
            
            # Mostrar informaciÃ³n de contexto si estÃ¡ disponible
            if enhanced_result.get("context_info"):
                context = enhanced_result["context_info"]
                print(f"   ğŸ¯ IntenciÃ³n detectada: {context.current_intent}")
                print(f"   ğŸ“‹ Entidades: {list(context.extracted_entities.keys())}")
                print(f"   ğŸ”„ Turno: {context.turn_count}")
            
            for resp in enhanced_result["responses"]:
                print(f"   ğŸ‘¤ Usuario: {resp['message']}")
                print(f"   ğŸ¤– Eva: {resp['response'][:150]}...")
                print()
        else:
            print(f"   âŒ Error: {enhanced_result.get('error', 'Unknown')}")
        
        # AnÃ¡lisis comparativo rÃ¡pido
        print("ğŸ” ANÃLISIS RÃPIDO:")
        if original_result["success"] and enhanced_result["success"]:
            time_diff = enhanced_result["execution_time"] - original_result["execution_time"]
            if time_diff < 0:
                print(f"   âš¡ Agente mejorado es {abs(time_diff):.2f}s mÃ¡s rÃ¡pido")
            else:
                print(f"   ğŸŒ Agente mejorado es {time_diff:.2f}s mÃ¡s lento (por mejor procesamiento)")
            
            # Comparar longitud de respuestas (aproximaciÃ³n de calidad)
            orig_length = sum(len(r["response"]) for r in original_result["responses"])
            enh_length = sum(len(r["response"]) for r in enhanced_result["responses"])
            
            if enh_length > orig_length:
                print(f"   ğŸ“ Respuestas mÃ¡s detalladas (+{enh_length - orig_length} caracteres)")
            
            # Verificar contexto
            if enhanced_result.get("context_info"):
                print(f"   ğŸ§  Contexto conversacional: âœ… Activo")
            else:
                print(f"   ğŸ§  Contexto conversacional: âŒ No disponible")
    
    def generate_summary_report(self):
        """Genera un reporte resumen de las mejoras"""
        print("\n" + "="*60)
        print("ğŸ“‹ REPORTE RESUMEN DE MEJORAS")
        print("="*60)
        
        successful_original = sum(1 for r in self.test_results if r["original"]["success"])
        successful_enhanced = sum(1 for r in self.test_results if r["enhanced"]["success"])
        total_scenarios = len(self.test_results)
        
        print(f"ğŸ“Š Escenarios exitosos:")
        print(f"   ğŸ”¸ Agente Original: {successful_original}/{total_scenarios}")
        print(f"   âœ¨ Agente Mejorado: {successful_enhanced}/{total_scenarios}")
        
        avg_time_original = sum(r["original"]["execution_time"] for r in self.test_results if r["original"]["success"]) / max(successful_original, 1)
        avg_time_enhanced = sum(r["enhanced"]["execution_time"] for r in self.test_results if r["enhanced"]["success"]) / max(successful_enhanced, 1)
        
        print(f"\nâ±ï¸  Tiempo promedio de respuesta:")
        print(f"   ğŸ”¸ Agente Original: {avg_time_original:.2f}s")
        print(f"   âœ¨ Agente Mejorado: {avg_time_enhanced:.2f}s")
        
        print(f"\nğŸ¯ MEJORAS IMPLEMENTADAS:")
        print(f"   âœ… ClasificaciÃ³n de intenciones mÃ¡s robusta")
        print(f"   âœ… Manejo de contexto conversacional")
        print(f"   âœ… ExtracciÃ³n de entidades mejorada")
        print(f"   âœ… Prompts mÃ¡s naturales y conversacionales")
        print(f"   âœ… Mejor manejo de errores y fallbacks")
        print(f"   âœ… Respuestas mÃ¡s empÃ¡ticas y personalizadas")
        
        print(f"\nğŸš€ RECOMENDACIONES:")
        print(f"   ğŸ’¡ Usar el agente mejorado para atenciÃ³n al cliente")
        print(f"   ğŸ’¡ Monitorear mÃ©tricas de satisfacciÃ³n del cliente")
        print(f"   ğŸ’¡ Entrenar con mÃ¡s datos conversacionales si estÃ¡n disponibles")
        print(f"   ğŸ’¡ Implementar feedback loop para mejora continua")

async def main():
    """FunciÃ³n principal"""
    print("ğŸ†š COMPARACIÃ“N DE AGENTES DE ATENCIÃ“N AL CLIENTE")
    print("ğŸ“ˆ Agente Original vs Agente Mejorado")
    print("=" * 60)
    
    # Inicializar comparador
    comparator = AgentComparison()
    
    try:
        # Inicializar agentes
        await comparator.initialize_agents()
        
        # Ejecutar comparaciÃ³n
        await comparator.run_comparison()
        
        # Generar reporte
        comparator.generate_summary_report()
        
        print(f"\nâœ… ComparaciÃ³n completada!")
        print(f"ğŸ“Š Se probaron {len(comparator.test_results)} escenarios")
        print(f"ğŸ¯ El agente mejorado muestra mejor manejo conversacional")
        
    except Exception as e:
        print(f"âŒ Error durante la comparaciÃ³n: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 