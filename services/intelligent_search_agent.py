"""
Agente Inteligente de B√∫squeda
Este agente usa IA para entender CUALQUIER petici√≥n del usuario y convertirla
en la b√∫squeda √≥ptima para encontrar productos en la base de datos.

FILOSOF√çA: La IA hace el trabajo pesado de entender al usuario,
no necesitamos l√≥gica r√≠gida ni casos especiales.
"""

import os
import json
import logging
from typing import Dict, Any, List, Optional
import aiohttp
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv("env.agent")

logger = logging.getLogger(__name__)

class IntelligentSearchAgent:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.model = "gpt-4o-mini"  # Modelo r√°pido y eficiente
        
        if not self.api_key:
            logger.warning("‚ö†Ô∏è OPENAI_API_KEY no configurada en env.agent")
        
    async def understand_user_request(self, user_message: str) -> Dict[str, Any]:
        """
        Entiende CUALQUIER petici√≥n del usuario y la convierte en una b√∫squeda estructurada.
        No hay casos especiales, no hay l√≥gica r√≠gida, solo IA entendiendo al usuario.
        """
        
        logger.info("=" * 60)
        logger.info("ü§ñ AGENTE INTELIGENTE ACTIVADO")
        logger.info(f"üìù Analizando: '{user_message}'")
        logger.info("=" * 60)
        
        prompt = f'''
Eres un experto en productos el√©ctricos de la tienda El Corte El√©ctrico.
Tu trabajo es entender lo que el cliente quiere y convertirlo en la b√∫squeda perfecta.

PETICI√ìN DEL CLIENTE: "{user_message}"

CONOCIMIENTO DE LA TIENDA:
Vendemos productos el√©ctricos como:
- Protecciones: diferenciales, magnetot√©rmicos (autom√°ticos/PIA), fusibles
- Cables: mangueras, hilos, enrollacables  
- Iluminaci√≥n: l√°mparas, bombillas, campanas industriales, proyectores
- Calefacci√≥n: termos, calentadores, radiadores, toalleros
- Comunicaci√≥n: porteros, videoporteros, telefonillos
- Industrial: transformadores, contactores, variadores
- Accesorios: bridas, canaletas, cajas, tubos

SIN√ìNIMOS IMPORTANTES (el cliente puede usar cualquiera):
- "autom√°tico" = magnetot√©rmico, PIA, disyuntor
- "diferencial" = llave diferencial, protecci√≥n de personas
- "fusibles" = plomos, cortacircuitos
- "l√°mpara para f√°brica/nave" = campana industrial, luminaria industrial
- "termo" = calentador de agua
- "recoge cables" = enrollacables, organizador cables
- "cintillos" = bridas, abrazaderas
- "ladr√≥n" = regleta, prolongador
- "casquillo" = portal√°mparas
- "telefonillo" = portero, intercomunicador

MARCAS QUE VENDEMOS:
Schneider, Legrand, Simon, Jung, ABB, Siemens, Hager, Chint, Gave, Orbis, Toscano

ANALIZA la petici√≥n y devuelve:
{{
    "search_query": "la mejor query para buscar en la BD (incluye sin√≥nimos)",
    "product_type": "tipo de producto que busca",
    "brand": "marca si la menciona o null",
    "specifications": {{
        "amperaje": "16A" (si lo menciona),
        "voltaje": "230V" (si lo menciona),
        "sensibilidad": "30mA" (para diferenciales),
        "polos": "2P" (si lo menciona),
        "potencia": "2000W" (si lo menciona),
        "otros": "cualquier otra especificaci√≥n"
    }},
    "intent": "comprar/consultar_precio/verificar_stock/comparar",
    "context": "uso dom√©stico/industrial/comercial (si lo menciona)",
    "original_request": "lo que pidi√≥ el cliente limpio de saludos"
}}

REGLAS CR√çTICAS:
1. IGNORA COMPLETAMENTE estas palabras de transici√≥n/confirmaci√≥n:
   - "bien", "ok", "vale", "perfecto", "genial", "ahora", "tambi√©n", "adem√°s"
   - "hola", "por favor", "gracias", "buenos d√≠as", "buenas tardes"
2. Si el mensaje empieza con "bien, ahora quiero..." ‚Üí IGNORA "bien, ahora" y enf√≥cate en lo que quiere
3. NUNCA uses palabras de transici√≥n como t√©rmino de b√∫squeda
4. EXTRAE solo el PRODUCTO REAL que busca el usuario
5. Si no hay un producto claro, devuelve search_query vac√≠a
6. EXPANDE con sin√≥nimos relevantes del sector
7. Para uso industrial/f√°brica/almac√©n: priorizar productos industriales

EJEMPLOS:

Cliente: "hola quiero un diferencial para un local comercial"
Respuesta: {{
    "search_query": "diferencial interruptor diferencial llave diferencial 30mA 300mA comercial",
    "product_type": "diferencial",
    "brand": null,
    "specifications": {{}},
    "intent": "comprar",
    "context": "comercial",
    "original_request": "diferencial para local comercial"
}}

Cliente: "necesito un autom√°tico de 16A schneider"
Respuesta: {{
    "search_query": "magnetot√©rmico autom√°tico PIA 16A schneider",
    "product_type": "magnetot√©rmico",
    "brand": "schneider",
    "specifications": {{"amperaje": "16A"}},
    "intent": "comprar",
    "context": null,
    "original_request": "autom√°tico 16A schneider"
}}

Cliente: "l√°mpara para una nave industrial"
Respuesta: {{
    "search_query": "campana industrial luminaria industrial proyector industrial alto bay LED nave",
    "product_type": "iluminaci√≥n industrial",
    "brand": null,
    "specifications": {{}},
    "intent": "comprar",
    "context": "industrial",
    "original_request": "l√°mpara para nave industrial"
}}

Cliente: "bien, ahora quiero un ventilador tambi√©n para f√°brica"
Respuesta: {{
    "search_query": "ventilador industrial extractor aire f√°brica nave",
    "product_type": "ventilador industrial",
    "brand": null,
    "specifications": {{}},
    "intent": "comprar",
    "context": "industrial",
    "original_request": "ventilador para f√°brica"
}}

Cliente: "ok perfecto"
Respuesta: {{
    "search_query": "",
    "product_type": null,
    "brand": null,
    "specifications": {{}},
    "intent": "confirmaci√≥n",
    "context": null,
    "original_request": "confirmaci√≥n"
}}
'''

        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": "Eres un experto analizador de peticiones de productos el√©ctricos. SIEMPRE respondes con JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,  # Baja temperatura para respuestas consistentes
                "max_tokens": 500,
                "response_format": {"type": "json_object"}  # Forzar respuesta JSON
            }
            
            logger.info(f"üöÄ Llamando a OpenAI API con modelo: {self.model}")
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status != 200:
                        error = await response.text()
                        logger.error(f"Error en OpenAI API: {error}")
                        return self._fallback_analysis(user_message)
                    
                    result = await response.json()
                    content = result['choices'][0]['message']['content']
                    
                    try:
                        analysis = json.loads(content)
                        logger.info(f"‚ú® An√°lisis inteligente completado:")
                        logger.info(f"   Query: {analysis.get('search_query')}")
                        logger.info(f"   Tipo: {analysis.get('product_type')}")
                        logger.info(f"   Marca: {analysis.get('brand')}")
                        return analysis
                    except json.JSONDecodeError:
                        logger.error(f"Error parseando JSON: {content}")
                        return self._fallback_analysis(user_message)
                        
        except Exception as e:
            logger.error(f"Error en an√°lisis inteligente: {e}")
            return self._fallback_analysis(user_message)
    
    def _fallback_analysis(self, user_message: str) -> Dict[str, Any]:
        """
        An√°lisis b√°sico de fallback si falla la IA
        """
        # Eliminar saludos comunes
        message = user_message.lower()
        for greeting in ['hola', 'buenos d√≠as', 'buenas tardes', 'por favor', 'gracias']:
            message = message.replace(greeting, '').strip()
        
        return {
            "search_query": message,
            "product_type": "producto",
            "brand": None,
            "specifications": {},
            "intent": "comprar",
            "context": None,
            "original_request": message
        }
    
    async def should_refine_results(
        self, 
        results: List[Dict],
        user_analysis: Dict[str, Any]
    ) -> tuple[bool, Optional[str]]:
        """
        Decide si los resultados necesitan refinamiento.
        Usa IA para tomar decisiones inteligentes, no reglas r√≠gidas.
        """
        
        if not results:
            return False, None
            
        if len(results) <= 5:
            # Pocos resultados, no necesita refinamiento
            return False, None
            
        if len(results) <= 10 and user_analysis.get('brand'):
            # Si especific√≥ marca y hay pocos resultados, mostrar todos
            return False, None
            
        # Para muchos resultados, preguntar a la IA qu√© hacer
        prompt = f'''
El cliente busca: {user_analysis.get('original_request')}
Encontramos {len(results)} productos.

Los primeros 5 son:
{self._format_results_for_ai(results[:5])}

¬øDebemos refinar la b√∫squeda o mostrar estos resultados?

Si hay que refinar, sugiere UNA pregunta corta y clara para el cliente.
Por ejemplo:
- "¬øDe qu√© marca lo prefieres? Tenemos: Schneider, Legrand, Simon"
- "¬øQu√© amperaje necesitas? Disponibles: 10A, 16A, 25A"
- "¬øPara uso dom√©stico o industrial?"

Responde con JSON:
{{
    "needs_refinement": true/false,
    "refinement_message": "pregunta al cliente" o null
}}
'''

        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": "Eres un asistente de ventas experto. Decides si mostrar productos o hacer una pregunta para refinar."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 200,
                "response_format": {"type": "json_object"}
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=data
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        content = result['choices'][0]['message']['content']
                        decision = json.loads(content)
                        
                        return (
                            decision.get('needs_refinement', False),
                            decision.get('refinement_message')
                        )
                        
        except Exception as e:
            logger.error(f"Error decidiendo refinamiento: {e}")
            
        # Fallback: si hay muchos resultados, sugerir refinamiento b√°sico
        if len(results) > 15:
            return True, f"Encontr√© {len(results)} opciones. ¬øPodr√≠as ser m√°s espec√≠fico sobre lo que necesitas?"
        
        return False, None
    
    def _format_results_for_ai(self, results: List[Dict]) -> str:
        """Formatea resultados para el an√°lisis de la IA"""
        formatted = []
        for i, r in enumerate(results, 1):
            title = r.get('title', 'Sin t√≠tulo')
            price = r.get('metadata', {}).get('price', 'Sin precio')
            formatted.append(f"{i}. {title} - {price}")
        return "\n".join(formatted)

# Instancia singleton
intelligent_search = IntelligentSearchAgent()